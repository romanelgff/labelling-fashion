{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We explored the labels and sublabel structure of our data, and decided to break it into several, smaller objectives that are solvable by a single model. The first of these is the primary classification, that is to label the image to one of three options (glasses/sunglasses, trousers/jeans, shoes).\n",
    "\n",
    "First, we need to think about what our approach would be.\n",
    "* 1) Complex network architecture that we try to optimse (find the best hyperparameters)\n",
    "* 2) Try out many different architectures without much effort into optimising them\n",
    "The truth is, as always, somewhere in the middle.\n",
    "\n",
    "Limitations:\n",
    "* passable model can be made in 2 weeks !\n",
    "* good model in 3 months !\n",
    "* great model in 1 year !\n",
    "\n",
    "The plan for this project:\n",
    "* 1) Concentrate on primary classification\n",
    "* 2) Considering the best approach for the Trousers and Jeans category\n",
    "* 3) Applying the techniques of L2 regularisation, dropout and data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import itertools\n",
    "\n",
    "import numpy as np # for the datasets\n",
    "import sklearn.metrics\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorboard.plugins.hparams import api as hp\n",
    "\n",
    "import matplotlib.pyplot as plt # for the cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the datasets\n",
    "data_train = np.load(r\"Dataset/Primary categories - Train.npz\") # .npz format is a numpy extension for storing multiple numpy arrays (contains 2 arrays: \"labels\" and \"images\")\n",
    "data_val = np.load(r\"Dataset/Primary categories - Validation.npz\")\n",
    "data_test = np.load(r\"Dataset/Primary categories - Test.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting the arrays from the imported data\n",
    "images_train = data_train['images']\n",
    "labels_train = data_train['labels']\n",
    "\n",
    "images_val = data_val['images']\n",
    "labels_val = data_val['labels']\n",
    "\n",
    "images_test = data_test['images']\n",
    "labels_test = data_test['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling the pixel values of all images\n",
    "images_train = images_train/255.0\n",
    "images_val = images_val/255.0\n",
    "images_test = images_test/255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When working with arrays:\n",
    "* Scaling the data is easy\n",
    "* TensorFlow can automatically shuffle and batch the dataset. This is done in the '.fit()' method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to use the same structure as the one we had in the MNIST example, given the forms of the images which are clearly different (horizontal, vetical and transparent)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3x4=12 combinations to test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining constants\n",
    "EPOCHS = 15 # to prevent the training from becoming too long\n",
    "BATCH_SIZE = 64 # not an hyperparameter to tune (in general, the batch size may affect the speed of the training, but not the accuracy* not true for every network, dataset and problem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the hyperparameters we would tune, and their values to be tested\n",
    "HP_FILTER_SIZE = hp.HParam('filter_size', hp.Discrete([3,5,7]))\n",
    "HP_FILTER_NUM = hp.HParam('filters_number', hp.Discrete([32,64,96,128]))\n",
    "\n",
    "METRIC_ACCURACY = 'accuracy'\n",
    "\n",
    "# Logging setup info\n",
    "with tf.summary.create_file_writer(r'Logs/Model 1/hparam_tuning/').as_default():\n",
    "    hp.hparams_config(\n",
    "        hparams=[HP_FILTER_SIZE, HP_FILTER_NUM],\n",
    "        metrics=[hp.Metric(METRIC_ACCURACY, display_name='Accuracy')],\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logs structure:\n",
    "\n",
    "Logs folder where every log is written to. Inside there are folders for the different models we will test:\n",
    "* Model 1: in every such mdoel folder resides two types of logs (hparam_tuning, fit=training process log)\n",
    "* Model 2: same\n",
    "* ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrapping our model and training in a function\n",
    "def train_test_model(hparams, session_num):\n",
    "    \n",
    "    # Outlining the model/architecture of our CNN\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Conv2D(hparams[HP_FILTER_NUM], hparams[HP_FILTER_SIZE], activation='relu', input_shape=(120,90,3)),\n",
    "        tf.keras.layers.MaxPooling2D(pool_size=(2,2)),\n",
    "        tf.keras.layers.Conv2D(hparams[HP_FILTER_NUM], 3, activation='relu'),\n",
    "        tf.keras.layers.MaxPooling2D(pool_size=(2,2)),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(3)\n",
    "    ])\n",
    "    \n",
    "    # Defining the loss function\n",
    "    loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "    # Compiling the model\n",
    "    model.compile(optimizer='adam', loss=loss_fn, metrics=['accuracy'])\n",
    "\n",
    "    # Defining the logging directory\n",
    "    log_dir = \"Logs/Model 1/fit/\" + \"run-{}\".format(session_num)\n",
    "    \n",
    "    \n",
    "    def plot_confusion_matrix(cm, class_names):\n",
    "        \"\"\"\n",
    "        Returns a matplotlib figure containing the plotted confusion matrix.\n",
    "\n",
    "        Args:\n",
    "          cm (array, shape = [n, n]): a confusion matrix of integer classes\n",
    "          class_names (array, shape = [n]): String names of the integer classes\n",
    "        \"\"\"\n",
    "        figure = plt.figure(figsize=(12, 12))\n",
    "        plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "        plt.title(\"Confusion matrix\")\n",
    "        plt.colorbar()\n",
    "        tick_marks = np.arange(len(class_names))\n",
    "        plt.xticks(tick_marks, class_names, rotation=45)\n",
    "        plt.yticks(tick_marks, class_names)\n",
    "\n",
    "        # Normalize the confusion matrix.\n",
    "        cm = np.around(cm.astype('float') / cm.sum(axis=1)[:, np.newaxis], decimals=2)\n",
    "\n",
    "        # Use white text if squares are dark; otherwise black.\n",
    "        threshold = cm.max() / 2.\n",
    "        for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "            color = \"white\" if cm[i, j] > threshold else \"black\"\n",
    "            plt.text(j, i, cm[i, j], horizontalalignment=\"center\", color=color)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.ylabel('True label')\n",
    "        plt.xlabel('Predicted label')\n",
    "        return figure\n",
    "    \n",
    "    \n",
    "    \n",
    "    def plot_to_image(figure):\n",
    "        \"\"\"Converts the matplotlib plot specified by 'figure' to a PNG image and\n",
    "        returns it. The supplied figure is closed and inaccessible after this call.\"\"\"\n",
    "        # Save the plot to a PNG in memory.\n",
    "        buf = io.BytesIO()\n",
    "        plt.savefig(buf, format='png')\n",
    "        # Closing the figure prevents it from being displayed directly inside\n",
    "        # the notebook.\n",
    "        plt.close(figure)\n",
    "        buf.seek(0)\n",
    "        # Convert PNG buffer to TF image\n",
    "        image = tf.image.decode_png(buf.getvalue(), channels=4)\n",
    "        # Add the batch dimension\n",
    "        image = tf.expand_dims(image, 0)\n",
    "        return image\n",
    "    \n",
    "    \n",
    "    # Defining a file writer for Confusion Matrix logging purposes\n",
    "    file_writer_cm = tf.summary.create_file_writer(log_dir + '/cm')     \n",
    "    \n",
    "    \n",
    "    def log_confusion_matrix(epoch, logs):\n",
    "        # Use the model to predict the values from the validation dataset.\n",
    "        test_pred_raw = model.predict(images_val)\n",
    "        test_pred = np.argmax(test_pred_raw, axis=1)\n",
    "\n",
    "        # Calculate the confusion matrix.\n",
    "        cm = sklearn.metrics.confusion_matrix(labels_val, test_pred)\n",
    "        # Log the confusion matrix as an image summary.\n",
    "        figure = plot_confusion_matrix(cm, class_names=['Glasses/Sunglasses', 'Trousers/Jeans', 'Shoes'])\n",
    "        cm_image = plot_to_image(figure)\n",
    "\n",
    "        # Log the confusion matrix as an image summary.\n",
    "        with file_writer_cm.as_default():\n",
    "            tf.summary.image(\"Confusion Matrix\", cm_image, step=epoch)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Define the Tensorboard and Confusion Matrix callbacks.\n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1, profile_batch=0)\n",
    "    cm_callback = tf.keras.callbacks.LambdaCallback(on_epoch_end=log_confusion_matrix)\n",
    "\n",
    "    \n",
    "    # Defining early stopping to prevent overfitting\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "        monitor = 'val_loss',\n",
    "        mode = 'auto',\n",
    "        min_delta = 0,\n",
    "        patience = 2,\n",
    "        verbose = 0, \n",
    "        restore_best_weights = True\n",
    "    )\n",
    "    \n",
    "    # Training the model\n",
    "    model.fit(\n",
    "        images_train,\n",
    "        labels_train,\n",
    "        epochs = EPOCHS,\n",
    "        batch_size = BATCH_SIZE, # if the batch_size parameter is set, TensorFlow would automatically SHUFFLE and BATCH the NumPy arrays (that is why we didn't do this earlier)\n",
    "        callbacks = [tensorboard_callback, cm_callback, early_stopping],\n",
    "        validation_data = (images_val,labels_val), # tuple of the numpy arrays\n",
    "        verbose = 2 # verbosity to 2 = limited printable information as to not clutter the screen\n",
    "    )\n",
    "    \n",
    "    \n",
    "    # Evaluating the model's performance on the validation set\n",
    "    _, accuracy = model.evaluate(images_val,labels_val) # important to make this evluation on the validation set and not on the test set, as we are yet to finalise the model\n",
    "    \n",
    "    # the model at that point is lost, as the variable that contains it is lost (the local variable is not logged!)\n",
    "    # so if want to test the model with a different dataset or continue the training we won't be able to do it\n",
    "    # hence, we will also export the model:\n",
    "    # Saving the current model for future reference\n",
    "    model.save(r\"saved_models/Model 1/Run-{}\".format(session_num)) # takes a lot of space so be careful\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a function to log the resuls\n",
    "def run(log_dir, hparams, session_num):\n",
    "    \n",
    "    with tf.summary.create_file_writer(log_dir).as_default():\n",
    "        hp.hparams(hparams)  # record the values used in this trial\n",
    "        accuracy = train_test_model(hparams, session_num)\n",
    "        tf.summary.scalar(METRIC_ACCURACY, accuracy, step=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting trial: run-1\n",
      "{'filter_size': 3, 'filters_number': 32}\n",
      "Epoch 1/15\n",
      "203/203 - 120s - loss: 0.0946 - accuracy: 0.9716 - val_loss: 0.0164 - val_accuracy: 0.9957\n",
      "Epoch 2/15\n",
      "203/203 - 116s - loss: 0.0152 - accuracy: 0.9978 - val_loss: 0.0140 - val_accuracy: 0.9969\n",
      "Epoch 3/15\n",
      "203/203 - 108s - loss: 0.0102 - accuracy: 0.9985 - val_loss: 0.0024 - val_accuracy: 0.9994\n",
      "Epoch 4/15\n",
      "203/203 - 118s - loss: 0.0087 - accuracy: 0.9988 - val_loss: 0.0023 - val_accuracy: 0.9994\n",
      "Epoch 5/15\n",
      "203/203 - 102s - loss: 0.0042 - accuracy: 0.9996 - val_loss: 0.0126 - val_accuracy: 0.9951\n",
      "Epoch 6/15\n",
      "203/203 - 125s - loss: 0.0058 - accuracy: 0.9991 - val_loss: 0.0147 - val_accuracy: 0.9975\n",
      "51/51 [==============================] - 4s 84ms/step - loss: 0.0023 - accuracy: 0.9994ETA: 1s\n",
      "INFO:tensorflow:Assets written to: saved_models/Model 1/Run-1/assets\n",
      "--- Starting trial: run-2\n",
      "{'filter_size': 3, 'filters_number': 64}\n",
      "Epoch 1/15\n",
      "203/203 - 244s - loss: 0.0905 - accuracy: 0.9759 - val_loss: 0.0059 - val_accuracy: 0.9988\n",
      "Epoch 2/15\n",
      "203/203 - 222s - loss: 0.0127 - accuracy: 0.9986 - val_loss: 0.0022 - val_accuracy: 0.9994\n",
      "Epoch 3/15\n",
      "203/203 - 202s - loss: 0.0100 - accuracy: 0.9989 - val_loss: 0.0036 - val_accuracy: 0.9994\n",
      "Epoch 4/15\n",
      "203/203 - 203s - loss: 0.0090 - accuracy: 0.9986 - val_loss: 0.0027 - val_accuracy: 0.9994\n",
      "51/51 [==============================] - 6s 121ms/step - loss: 0.0022 - accuracy: 0.9994\n",
      "INFO:tensorflow:Assets written to: saved_models/Model 1/Run-2/assets\n",
      "--- Starting trial: run-3\n",
      "{'filter_size': 3, 'filters_number': 96}\n",
      "Epoch 1/15\n",
      "203/203 - 332s - loss: 0.0973 - accuracy: 0.9708 - val_loss: 0.0099 - val_accuracy: 0.9975\n",
      "Epoch 2/15\n",
      "203/203 - 326s - loss: 0.0131 - accuracy: 0.9984 - val_loss: 0.0071 - val_accuracy: 0.9988\n",
      "Epoch 3/15\n",
      "203/203 - 329s - loss: 0.0102 - accuracy: 0.9985 - val_loss: 0.0029 - val_accuracy: 0.9994\n",
      "Epoch 4/15\n",
      "203/203 - 326s - loss: 0.0067 - accuracy: 0.9994 - val_loss: 0.0045 - val_accuracy: 0.9981\n",
      "Epoch 5/15\n",
      "203/203 - 756s - loss: 0.0047 - accuracy: 0.9992 - val_loss: 0.0269 - val_accuracy: 0.9951\n",
      "51/51 [==============================] - 9s 183ms/step - loss: 0.0029 - accuracy: 0.9994\n",
      "INFO:tensorflow:Assets written to: saved_models/Model 1/Run-3/assets\n",
      "--- Starting trial: run-4\n",
      "{'filter_size': 3, 'filters_number': 128}\n",
      "Epoch 1/15\n",
      "203/203 - 539s - loss: 0.0805 - accuracy: 0.9789 - val_loss: 0.0029 - val_accuracy: 0.9994\n",
      "Epoch 2/15\n",
      "203/203 - 539s - loss: 0.0146 - accuracy: 0.9977 - val_loss: 0.0035 - val_accuracy: 0.9988\n",
      "Epoch 3/15\n",
      "203/203 - 471s - loss: 0.0144 - accuracy: 0.9968 - val_loss: 0.0162 - val_accuracy: 0.9975\n",
      "51/51 [==============================] - 16s 308ms/step - loss: 0.0029 - accuracy: 0.9994\n",
      "INFO:tensorflow:Assets written to: saved_models/Model 1/Run-4/assets\n",
      "--- Starting trial: run-5\n",
      "{'filter_size': 5, 'filters_number': 32}\n",
      "Epoch 1/15\n",
      "203/203 - 108s - loss: 0.0849 - accuracy: 0.9725 - val_loss: 0.0072 - val_accuracy: 0.9988\n",
      "Epoch 2/15\n",
      "203/203 - 142s - loss: 0.0145 - accuracy: 0.9978 - val_loss: 0.0056 - val_accuracy: 0.9988\n",
      "Epoch 3/15\n",
      "203/203 - 126s - loss: 0.0093 - accuracy: 0.9994 - val_loss: 0.0056 - val_accuracy: 0.9981\n",
      "Epoch 4/15\n",
      "203/203 - 107s - loss: 0.0074 - accuracy: 0.9994 - val_loss: 0.0038 - val_accuracy: 0.9988\n",
      "Epoch 5/15\n",
      "203/203 - 107s - loss: 0.0092 - accuracy: 0.9981 - val_loss: 0.0060 - val_accuracy: 0.9981\n",
      "Epoch 6/15\n",
      "203/203 - 124s - loss: 0.0086 - accuracy: 0.9985 - val_loss: 0.0078 - val_accuracy: 0.9981\n",
      "51/51 [==============================] - 4s 70ms/step - loss: 0.0038 - accuracy: 0.9988\n",
      "INFO:tensorflow:Assets written to: saved_models/Model 1/Run-5/assets\n",
      "--- Starting trial: run-6\n",
      "{'filter_size': 5, 'filters_number': 64}\n",
      "Epoch 1/15\n",
      "203/203 - 316s - loss: 0.0873 - accuracy: 0.9733 - val_loss: 0.0141 - val_accuracy: 0.9981\n",
      "Epoch 2/15\n",
      "203/203 - 282s - loss: 0.0167 - accuracy: 0.9977 - val_loss: 0.0115 - val_accuracy: 0.9981\n",
      "Epoch 3/15\n",
      "203/203 - 281s - loss: 0.0171 - accuracy: 0.9971 - val_loss: 0.0099 - val_accuracy: 0.9981\n",
      "Epoch 4/15\n",
      "203/203 - 235s - loss: 0.0095 - accuracy: 0.9986 - val_loss: 0.0152 - val_accuracy: 0.9969\n",
      "Epoch 5/15\n",
      "203/203 - 225s - loss: 0.0077 - accuracy: 0.9988 - val_loss: 0.0269 - val_accuracy: 0.9914\n",
      "51/51 [==============================] - 7s 132ms/step - loss: 0.0099 - accuracy: 0.9981\n",
      "INFO:tensorflow:Assets written to: saved_models/Model 1/Run-6/assets\n",
      "--- Starting trial: run-7\n",
      "{'filter_size': 5, 'filters_number': 96}\n",
      "Epoch 1/15\n",
      "203/203 - 2176s - loss: 0.1070 - accuracy: 0.9729 - val_loss: 0.0142 - val_accuracy: 0.9969\n",
      "Epoch 2/15\n",
      "203/203 - 429s - loss: 0.0244 - accuracy: 0.9961 - val_loss: 0.0146 - val_accuracy: 0.9957\n",
      "Epoch 3/15\n",
      "203/203 - 447s - loss: 0.0127 - accuracy: 0.9989 - val_loss: 0.0113 - val_accuracy: 0.9975\n",
      "Epoch 4/15\n",
      "203/203 - 448s - loss: 0.0076 - accuracy: 0.9992 - val_loss: 0.0113 - val_accuracy: 0.9975\n",
      "Epoch 5/15\n",
      "203/203 - 450s - loss: 0.0088 - accuracy: 0.9983 - val_loss: 0.0123 - val_accuracy: 0.9988\n",
      "51/51 [==============================] - 15s 293ms/step - loss: 0.0113 - accuracy: 0.9975\n",
      "INFO:tensorflow:Assets written to: saved_models/Model 1/Run-7/assets\n",
      "--- Starting trial: run-8\n",
      "{'filter_size': 5, 'filters_number': 128}\n",
      "Epoch 1/15\n",
      "203/203 - 691s - loss: 0.1045 - accuracy: 0.9669 - val_loss: 0.0234 - val_accuracy: 0.9932\n",
      "Epoch 2/15\n",
      "203/203 - 9852s - loss: 0.0206 - accuracy: 0.9965 - val_loss: 0.0062 - val_accuracy: 0.9981\n",
      "Epoch 3/15\n",
      "203/203 - 14617s - loss: 0.0122 - accuracy: 0.9985 - val_loss: 0.0123 - val_accuracy: 0.9975\n",
      "Epoch 4/15\n",
      "203/203 - 545s - loss: 0.0082 - accuracy: 0.9988 - val_loss: 0.0083 - val_accuracy: 0.9988\n",
      "51/51 [==============================] - 17s 327ms/step - loss: 0.0062 - accuracy: 0.9981\n",
      "INFO:tensorflow:Assets written to: saved_models/Model 1/Run-8/assets\n",
      "--- Starting trial: run-9\n",
      "{'filter_size': 7, 'filters_number': 32}\n",
      "Epoch 1/15\n",
      "203/203 - 133s - loss: 0.1104 - accuracy: 0.9674 - val_loss: 0.0090 - val_accuracy: 0.9988\n",
      "Epoch 2/15\n",
      "203/203 - 126s - loss: 0.0155 - accuracy: 0.9984 - val_loss: 0.0064 - val_accuracy: 0.9988\n",
      "Epoch 3/15\n",
      "203/203 - 126s - loss: 0.0113 - accuracy: 0.9986 - val_loss: 0.0051 - val_accuracy: 0.9988\n",
      "Epoch 4/15\n",
      "203/203 - 125s - loss: 0.0114 - accuracy: 0.9985 - val_loss: 0.0673 - val_accuracy: 0.9765\n",
      "Epoch 5/15\n",
      "203/203 - 125s - loss: 0.0106 - accuracy: 0.9983 - val_loss: 0.0062 - val_accuracy: 0.9981\n",
      "51/51 [==============================] - 4s 75ms/step - loss: 0.0051 - accuracy: 0.9988\n",
      "INFO:tensorflow:Assets written to: saved_models/Model 1/Run-9/assets\n",
      "--- Starting trial: run-10\n",
      "{'filter_size': 7, 'filters_number': 64}\n",
      "Epoch 1/15\n",
      "203/203 - 241s - loss: 0.0942 - accuracy: 0.9721 - val_loss: 0.0153 - val_accuracy: 0.9963\n",
      "Epoch 2/15\n",
      "203/203 - 244s - loss: 0.0226 - accuracy: 0.9958 - val_loss: 0.0080 - val_accuracy: 0.9981\n",
      "Epoch 3/15\n",
      "203/203 - 238s - loss: 0.0112 - accuracy: 0.9984 - val_loss: 0.0076 - val_accuracy: 0.9975\n",
      "Epoch 4/15\n",
      "203/203 - 243s - loss: 0.0075 - accuracy: 0.9988 - val_loss: 0.0090 - val_accuracy: 0.9975\n",
      "Epoch 5/15\n",
      "203/203 - 238s - loss: 0.0072 - accuracy: 0.9991 - val_loss: 0.0058 - val_accuracy: 0.9981\n",
      "Epoch 6/15\n",
      "203/203 - 240s - loss: 0.0054 - accuracy: 0.9992 - val_loss: 0.0042 - val_accuracy: 0.9981\n",
      "Epoch 7/15\n",
      "203/203 - 237s - loss: 0.0046 - accuracy: 0.9995 - val_loss: 0.0071 - val_accuracy: 0.9988\n",
      "Epoch 8/15\n",
      "203/203 - 241s - loss: 0.0042 - accuracy: 0.9998 - val_loss: 0.0152 - val_accuracy: 0.9969\n",
      "51/51 [==============================] - 7s 137ms/step - loss: 0.0042 - accuracy: 0.9981\n",
      "INFO:tensorflow:Assets written to: saved_models/Model 1/Run-10/assets\n",
      "--- Starting trial: run-11\n",
      "{'filter_size': 7, 'filters_number': 96}\n",
      "Epoch 1/15\n",
      "203/203 - 3423s - loss: 0.1291 - accuracy: 0.9593 - val_loss: 0.0121 - val_accuracy: 0.9975\n",
      "Epoch 2/15\n",
      "203/203 - 477s - loss: 0.0175 - accuracy: 0.9977 - val_loss: 0.0090 - val_accuracy: 0.9975\n",
      "Epoch 3/15\n",
      "203/203 - 481s - loss: 0.0138 - accuracy: 0.9982 - val_loss: 0.0118 - val_accuracy: 0.9975\n",
      "Epoch 4/15\n",
      "203/203 - 464s - loss: 0.0094 - accuracy: 0.9993 - val_loss: 0.0130 - val_accuracy: 0.9969\n",
      "51/51 [==============================] - 14s 264ms/step - loss: 0.0090 - accuracy: 0.9975\n",
      "INFO:tensorflow:Assets written to: saved_models/Model 1/Run-11/assets\n",
      "--- Starting trial: run-12\n",
      "{'filter_size': 7, 'filters_number': 128}\n",
      "Epoch 1/15\n",
      "203/203 - 663s - loss: 0.1092 - accuracy: 0.9674 - val_loss: 0.0073 - val_accuracy: 0.9981\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/15\n",
      "203/203 - 684s - loss: 0.0859 - accuracy: 0.9798 - val_loss: 0.0158 - val_accuracy: 0.9969\n",
      "Epoch 3/15\n",
      "203/203 - 554s - loss: 0.0211 - accuracy: 0.9974 - val_loss: 0.0050 - val_accuracy: 0.9988\n",
      "Epoch 4/15\n",
      "203/203 - 1627s - loss: 0.0147 - accuracy: 0.9982 - val_loss: 0.0060 - val_accuracy: 0.9988\n",
      "Epoch 5/15\n",
      "203/203 - 632s - loss: 0.0117 - accuracy: 0.9988 - val_loss: 0.0042 - val_accuracy: 0.9988\n",
      "Epoch 6/15\n",
      "203/203 - 656s - loss: 0.0083 - accuracy: 0.9989 - val_loss: 0.0064 - val_accuracy: 0.9994\n",
      "Epoch 7/15\n",
      "203/203 - 681s - loss: 0.0082 - accuracy: 0.9988 - val_loss: 0.0035 - val_accuracy: 0.9988\n",
      "Epoch 8/15\n",
      "203/203 - 659s - loss: 0.0050 - accuracy: 0.9995 - val_loss: 0.0040 - val_accuracy: 0.9988\n",
      "Epoch 9/15\n",
      "203/203 - 700s - loss: 0.0075 - accuracy: 0.9980 - val_loss: 0.0044 - val_accuracy: 0.9988\n",
      "51/51 [==============================] - 40s 786ms/step - loss: 0.0035 - accuracy: 0.9988\n",
      "INFO:tensorflow:Assets written to: saved_models/Model 1/Run-12/assets\n"
     ]
    }
   ],
   "source": [
    "session_num = 1\n",
    "\n",
    "for filter_size in HP_FILTER_SIZE.domain.values:\n",
    "    for filter_num in HP_FILTER_NUM.domain.values:\n",
    "\n",
    "        hparams = {\n",
    "            HP_FILTER_SIZE: filter_size,\n",
    "            HP_FILTER_NUM: filter_num\n",
    "        }\n",
    "\n",
    "        run_name = \"run-%d\" % session_num\n",
    "        print('--- Starting trial: %s' % run_name)\n",
    "        print({h.name: hparams[h] for h in hparams})\n",
    "        run('Logs/Model 1/hparam_tuning/' + run_name, hparams, session_num)\n",
    "\n",
    "        session_num += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading a model to evaluate on the test set\n",
    "model = tf.keras.models.load_model(r\"saved_models/Model 1/Run-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51/51 [==============================] - 7s 125ms/step - loss: 0.0191 - accuracy: 0.9988\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(images_test,labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.0191. Test accuracy: 99.88%\n"
     ]
    }
   ],
   "source": [
    "# Printing the test results\n",
    "print('Test loss: {0:.4f}. Test accuracy: {1:.2f}%'.format(test_loss, test_accuracy*100.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The task is so easy, that whatever we do on the hyperparameters we get more than 99.9% accuracy! (see tensorboard in next cell) Indeed, we can't really see any correlation (tab: scatter plot matrix view) between the hyperparameters and the accuracy computed, nor for the filter size neither for the filter number. That is the reason why we won't investigate the primary classification any further (no use of any regularisation technique or create different architectures)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ERROR: Timed out waiting for TensorBoard to start. It may still be running as pid 10473."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir \"Logs/Model 1/hparam_tuning\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-f4e7709e84fd519f\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-f4e7709e84fd519f\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6008;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir \"Logs/Model 1/fit\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recap:\n",
    "* Primary classification task to create a CNN that distinguish between an image of a shoe, trousers or glasses. \n",
    "* To achieve this, we set up a relatively simple model consisting of: 2 convotional layers, 2 maxpool layers and the compulsory dense outcome layer. \n",
    "* We decided to use this configuration because it keeps the training time lower, and allows us to check for different hyperparameters.\n",
    "* In terms of code, we imported datasets and preprocessed them, created the functions for hyperparameters tuning and confusion matrix and log the training process using TensorBoard.\n",
    "* We tried out the model with a filter size of 3, 5 and 7, and number of filters set to 32, 64, 96 and 128.\n",
    "* The results were impressive, with more than 99.9% accuracy accross all different combinations of hyerparamaters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
