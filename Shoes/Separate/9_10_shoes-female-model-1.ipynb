{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import itertools\n",
    "\n",
    "import numpy as np\n",
    "import sklearn.metrics\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorboard.plugins.hparams import api as hp\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the datasets\n",
    "data_train = np.load(r\"Dataset/Shoes - Female - Train.npz\")\n",
    "data_val = np.load(r\"Dataset/Shoes - Female - Validation.npz\")\n",
    "data_test = np.load(r\"Dataset/Shoes - Female - Test.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting the arrays from the imported data\n",
    "images_train = data_train['images']\n",
    "labels_train = data_train['labels']\n",
    "\n",
    "images_val = data_val['images']\n",
    "labels_val = data_val['labels']\n",
    "\n",
    "images_test = data_test['images']\n",
    "labels_test = data_test['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling the pixel values of all images\n",
    "images_train = images_train/255.0\n",
    "images_val = images_val/255.0\n",
    "images_test = images_test/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the hyperparameters we would tune, and their values to be tested\n",
    "HP_FILTER_SIZE_1 = hp.HParam('filter_size_1', hp.Discrete([3,5,7]))\n",
    "HP_FILTER_NUM = hp.HParam('filters_number', hp.Discrete([64,96,128]))\n",
    "HP_FILTER_SIZE_2 = hp.HParam('filter_size_2', hp.Discrete([3,5]))\n",
    "HP_DENSE_SIZE = hp.HParam('dense_size', hp.Discrete([256]))#,512,1024]))\n",
    "\n",
    "METRIC_ACCURACY = 'accuracy'\n",
    "\n",
    "# Logging setup info\n",
    "with tf.summary.create_file_writer(r'Logs/Model_Female/hparam_tuning/').as_default():\n",
    "    hp.hparams_config(\n",
    "        hparams=[HP_FILTER_SIZE_1, HP_FILTER_NUM, HP_FILTER_SIZE_2, HP_DENSE_SIZE],\n",
    "        metrics=[hp.Metric(METRIC_ACCURACY, display_name='Accuracy')],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 20\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrapping our model and training in a function\n",
    "def train_test_model(hparams, session_num):\n",
    "    \n",
    "    # Outlining the model/architecture of our CNN\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Conv2D(hparams[HP_FILTER_NUM], hparams[HP_FILTER_SIZE_1], activation='relu', input_shape=(120,90,3)),\n",
    "        tf.keras.layers.MaxPooling2D(pool_size=(2,2)),\n",
    "        tf.keras.layers.Conv2D(hparams[HP_FILTER_NUM], hparams[HP_FILTER_SIZE_2], activation='relu'),\n",
    "        tf.keras.layers.MaxPooling2D(pool_size=(2,2)),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(hparams[HP_DENSE_SIZE], activation='relu'),\n",
    "        tf.keras.layers.Dense(6)\n",
    "    ])\n",
    "    \n",
    "    # Defining the loss function\n",
    "    loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "    # Compiling the model\n",
    "    model.compile(optimizer='adam', loss=loss_fn, metrics=['accuracy'])\n",
    "    \n",
    "    # Defining the logging directory\n",
    "    log_dir = \"Logs/Model_Female/fit/\" + \"run-{}\".format(session_num)\n",
    "    \n",
    "    def plot_confusion_matrix(cm, class_names):\n",
    "        \"\"\"\n",
    "        Returns a matplotlib figure containing the plotted confusion matrix.\n",
    "\n",
    "        Args:\n",
    "          cm (array, shape = [n, n]): a confusion matrix of integer classes\n",
    "          class_names (array, shape = [n]): String names of the integer classes\n",
    "        \"\"\"\n",
    "        figure = plt.figure(figsize=(12, 12))\n",
    "        plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "        plt.title(\"Confusion matrix\")\n",
    "        plt.colorbar()\n",
    "        tick_marks = np.arange(len(class_names))\n",
    "        plt.xticks(tick_marks, class_names, rotation=45)\n",
    "        plt.yticks(tick_marks, class_names)\n",
    "\n",
    "        # Normalize the confusion matrix.\n",
    "        cm = np.around(cm.astype('float') / cm.sum(axis=1)[:, np.newaxis], decimals=2)\n",
    "\n",
    "        # Use white text if squares are dark; otherwise black.\n",
    "        threshold = cm.max() / 2.\n",
    "        for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "            color = \"white\" if cm[i, j] > threshold else \"black\"\n",
    "            plt.text(j, i, cm[i, j], horizontalalignment=\"center\", color=color)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.ylabel('True label')\n",
    "        plt.xlabel('Predicted label')\n",
    "        return figure  \n",
    "    \n",
    "    \n",
    "    def plot_to_image(figure):\n",
    "        \"\"\"Converts the matplotlib plot specified by 'figure' to a PNG image and\n",
    "        returns it. The supplied figure is closed and inaccessible after this call.\"\"\"\n",
    "        # Save the plot to a PNG in memory.\n",
    "        buf = io.BytesIO()\n",
    "        plt.savefig(buf, format='png')\n",
    "        # Closing the figure prevents it from being displayed directly inside\n",
    "        # the notebook.\n",
    "        plt.close(figure)\n",
    "        buf.seek(0)\n",
    "        # Convert PNG buffer to TF image\n",
    "        image = tf.image.decode_png(buf.getvalue(), channels=4)\n",
    "        # Add the batch dimension\n",
    "        image = tf.expand_dims(image, 0)\n",
    "        return image\n",
    "    \n",
    "    \n",
    "    # Defining a file writer for Confusion Matrix logging purposes\n",
    "    file_writer_cm = tf.summary.create_file_writer(log_dir + '/cm')\n",
    "    \n",
    "    \n",
    "    def log_confusion_matrix(epoch, logs):\n",
    "        # Use the model to predict the values from the validation dataset.\n",
    "        test_pred_raw = model.predict(images_val)\n",
    "        test_pred = np.argmax(test_pred_raw, axis=1)\n",
    "\n",
    "        # Calculate the confusion matrix.\n",
    "        cm = sklearn.metrics.confusion_matrix(labels_val, test_pred)\n",
    "        # Log the confusion matrix as an image summary.\n",
    "        figure = plot_confusion_matrix(cm, class_names=['Boots', 'Ballerina shoes', 'Trainers/Sneakers', 'High heels', 'Sandals/Flip flops/Slippers', 'Others'])\n",
    "        cm_image = plot_to_image(figure)\n",
    "\n",
    "        # Log the confusion matrix as an image summary.\n",
    "        with file_writer_cm.as_default():\n",
    "            tf.summary.image(\"Confusion Matrix\", cm_image, step=epoch)\n",
    "    \n",
    "    \n",
    "    # Define the Tensorboard and Confusion Matrix callbacks.\n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1, profile_batch=0)\n",
    "    cm_callback = tf.keras.callbacks.LambdaCallback(on_epoch_end=log_confusion_matrix)\n",
    "\n",
    "    \n",
    "    # Defining early stopping to prevent overfitting\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "        monitor = 'val_loss',\n",
    "        mode = 'auto',\n",
    "        min_delta = 0,\n",
    "        patience = 2,\n",
    "        verbose = 0, \n",
    "        restore_best_weights = True\n",
    "    )\n",
    "    \n",
    "    # Training the model\n",
    "    model.fit(\n",
    "        images_train,\n",
    "        labels_train,\n",
    "        epochs = EPOCHS,\n",
    "        batch_size = BATCH_SIZE,\n",
    "        callbacks = [tensorboard_callback, cm_callback, early_stopping],\n",
    "        validation_data = (images_val,labels_val),\n",
    "        verbose = 2\n",
    "    )\n",
    "    \n",
    "    \n",
    "    # Evaluating the model's performance on the validation set\n",
    "    _, accuracy = model.evaluate(images_val,labels_val)\n",
    "    \n",
    "    # Saving the current model for future reference\n",
    "    model.save(r\"saved_models/Model_Female/Run-{}\".format(session_num))\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a function to log the resuls\n",
    "def run(log_dir, hparams, session_num):\n",
    "    \n",
    "    with tf.summary.create_file_writer(log_dir).as_default():\n",
    "        hp.hparams(hparams)  # record the values used in this trial\n",
    "        accuracy = train_test_model(hparams, session_num)\n",
    "        tf.summary.scalar(METRIC_ACCURACY, accuracy, step=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting trial: run-1\n",
      "{'filter_size_1': 3, 'filters_number': 64, 'filter_size_2': 3, 'dense_size': 256}\n",
      "Epoch 1/20\n",
      "46/46 - 60s - loss: 1.3276 - accuracy: 0.5277 - val_loss: 0.6697 - val_accuracy: 0.7639\n",
      "Epoch 2/20\n",
      "46/46 - 52s - loss: 0.5513 - accuracy: 0.8139 - val_loss: 0.4640 - val_accuracy: 0.8500\n",
      "Epoch 3/20\n",
      "46/46 - 54s - loss: 0.4408 - accuracy: 0.8472 - val_loss: 0.4991 - val_accuracy: 0.8500\n",
      "Epoch 4/20\n",
      "46/46 - 56s - loss: 0.3634 - accuracy: 0.8770 - val_loss: 0.3957 - val_accuracy: 0.8611\n",
      "Epoch 5/20\n",
      "46/46 - 114s - loss: 0.2723 - accuracy: 0.9106 - val_loss: 0.4755 - val_accuracy: 0.8472\n",
      "Epoch 6/20\n",
      "46/46 - 105s - loss: 0.2467 - accuracy: 0.9189 - val_loss: 0.4897 - val_accuracy: 0.8528\n",
      "12/12 [==============================] - 4s 286ms/step - loss: 0.3957 - accuracy: 0.8611\n",
      "INFO:tensorflow:Assets written to: saved_models/Model_Female/Run-1/assets\n",
      "--- Starting trial: run-2\n",
      "{'filter_size_1': 3, 'filters_number': 64, 'filter_size_2': 5, 'dense_size': 256}\n",
      "Epoch 1/20\n",
      "46/46 - 180s - loss: 1.2884 - accuracy: 0.5631 - val_loss: 0.7140 - val_accuracy: 0.7556\n",
      "Epoch 2/20\n",
      "46/46 - 164s - loss: 0.5722 - accuracy: 0.8080 - val_loss: 0.4730 - val_accuracy: 0.8417\n",
      "Epoch 3/20\n",
      "46/46 - 155s - loss: 0.4005 - accuracy: 0.8649 - val_loss: 0.4862 - val_accuracy: 0.8500\n",
      "Epoch 4/20\n",
      "46/46 - 199s - loss: 0.3239 - accuracy: 0.8947 - val_loss: 0.3817 - val_accuracy: 0.8806\n",
      "Epoch 5/20\n",
      "46/46 - 179s - loss: 0.2662 - accuracy: 0.9096 - val_loss: 0.4769 - val_accuracy: 0.8667\n",
      "Epoch 6/20\n",
      "46/46 - 186s - loss: 0.1956 - accuracy: 0.9307 - val_loss: 0.4010 - val_accuracy: 0.8833\n",
      "12/12 [==============================] - 7s 546ms/step - loss: 0.3817 - accuracy: 0.8806\n",
      "INFO:tensorflow:Assets written to: saved_models/Model_Female/Run-2/assets\n",
      "--- Starting trial: run-3\n",
      "{'filter_size_1': 3, 'filters_number': 96, 'filter_size_2': 3, 'dense_size': 256}\n",
      "Epoch 1/20\n",
      "46/46 - 169s - loss: 1.7233 - accuracy: 0.5090 - val_loss: 0.7835 - val_accuracy: 0.7278\n",
      "Epoch 2/20\n",
      "46/46 - 165s - loss: 0.6058 - accuracy: 0.7952 - val_loss: 0.5241 - val_accuracy: 0.8389\n",
      "Epoch 3/20\n",
      "46/46 - 164s - loss: 0.4554 - accuracy: 0.8420 - val_loss: 0.5345 - val_accuracy: 0.8056\n",
      "Epoch 4/20\n",
      "46/46 - 181s - loss: 0.4322 - accuracy: 0.8552 - val_loss: 0.8558 - val_accuracy: 0.7556\n",
      "12/12 [==============================] - 5s 397ms/step - loss: 0.5241 - accuracy: 0.8389\n",
      "INFO:tensorflow:Assets written to: saved_models/Model_Female/Run-3/assets\n",
      "--- Starting trial: run-4\n",
      "{'filter_size_1': 3, 'filters_number': 96, 'filter_size_2': 5, 'dense_size': 256}\n",
      "Epoch 1/20\n",
      "46/46 - 310s - loss: 1.7185 - accuracy: 0.4737 - val_loss: 1.3339 - val_accuracy: 0.5083\n",
      "Epoch 2/20\n",
      "46/46 - 304s - loss: 0.7478 - accuracy: 0.7415 - val_loss: 0.6158 - val_accuracy: 0.8083\n",
      "Epoch 3/20\n",
      "46/46 - 285s - loss: 0.5372 - accuracy: 0.8257 - val_loss: 0.4403 - val_accuracy: 0.8833\n",
      "Epoch 4/20\n",
      "46/46 - 275s - loss: 0.4294 - accuracy: 0.8555 - val_loss: 0.4421 - val_accuracy: 0.8556\n",
      "Epoch 5/20\n",
      "46/46 - 309s - loss: 0.3949 - accuracy: 0.8666 - val_loss: 0.5634 - val_accuracy: 0.8222\n",
      "12/12 [==============================] - 10s 807ms/step - loss: 0.4403 - accuracy: 0.8833\n",
      "INFO:tensorflow:Assets written to: saved_models/Model_Female/Run-4/assets\n",
      "--- Starting trial: run-5\n",
      "{'filter_size_1': 3, 'filters_number': 128, 'filter_size_2': 3, 'dense_size': 256}\n",
      "Epoch 1/20\n",
      "46/46 - 283s - loss: 1.4776 - accuracy: 0.5177 - val_loss: 0.7341 - val_accuracy: 0.7611\n",
      "Epoch 2/20\n",
      "46/46 - 284s - loss: 0.6128 - accuracy: 0.7966 - val_loss: 0.6014 - val_accuracy: 0.7917\n",
      "Epoch 3/20\n",
      "46/46 - 236s - loss: 0.4236 - accuracy: 0.8565 - val_loss: 0.5321 - val_accuracy: 0.8306\n",
      "Epoch 4/20\n",
      "46/46 - 293s - loss: 0.4622 - accuracy: 0.8434 - val_loss: 0.6307 - val_accuracy: 0.8250\n",
      "Epoch 5/20\n",
      "46/46 - 251s - loss: 0.3398 - accuracy: 0.8812 - val_loss: 0.5120 - val_accuracy: 0.8250\n",
      "Epoch 6/20\n",
      "46/46 - 307s - loss: 0.3143 - accuracy: 0.8898 - val_loss: 0.4040 - val_accuracy: 0.8861\n",
      "Epoch 7/20\n",
      "46/46 - 270s - loss: 0.2194 - accuracy: 0.9234 - val_loss: 0.4259 - val_accuracy: 0.8639\n",
      "Epoch 8/20\n",
      "46/46 - 274s - loss: 0.1562 - accuracy: 0.9487 - val_loss: 0.3699 - val_accuracy: 0.8917\n",
      "Epoch 9/20\n",
      "46/46 - 277s - loss: 0.1301 - accuracy: 0.9577 - val_loss: 0.3845 - val_accuracy: 0.8806\n",
      "Epoch 10/20\n",
      "46/46 - 234s - loss: 0.1630 - accuracy: 0.9439 - val_loss: 0.4282 - val_accuracy: 0.8833\n",
      "12/12 [==============================] - 9s 685ms/step - loss: 0.3699 - accuracy: 0.8917\n",
      "INFO:tensorflow:Assets written to: saved_models/Model_Female/Run-5/assets\n",
      "--- Starting trial: run-6\n",
      "{'filter_size_1': 3, 'filters_number': 128, 'filter_size_2': 5, 'dense_size': 256}\n",
      "Epoch 1/20\n",
      "46/46 - 1314s - loss: 2.0897 - accuracy: 0.5499 - val_loss: 0.6492 - val_accuracy: 0.7750\n",
      "Epoch 2/20\n",
      "46/46 - 498s - loss: 0.7672 - accuracy: 0.7377 - val_loss: 0.5618 - val_accuracy: 0.8528\n",
      "Epoch 3/20\n",
      "46/46 - 521s - loss: 0.4709 - accuracy: 0.8399 - val_loss: 0.4588 - val_accuracy: 0.8417\n",
      "Epoch 4/20\n",
      "46/46 - 472s - loss: 0.4605 - accuracy: 0.8468 - val_loss: 0.4061 - val_accuracy: 0.8778\n",
      "Epoch 5/20\n",
      "46/46 - 406s - loss: 0.3426 - accuracy: 0.8843 - val_loss: 0.3641 - val_accuracy: 0.8806\n",
      "Epoch 6/20\n",
      "46/46 - 564s - loss: 0.2879 - accuracy: 0.9096 - val_loss: 0.4238 - val_accuracy: 0.8250\n",
      "Epoch 7/20\n",
      "46/46 - 537s - loss: 0.2479 - accuracy: 0.9165 - val_loss: 0.3437 - val_accuracy: 0.9056\n",
      "Epoch 8/20\n",
      "46/46 - 493s - loss: 0.1662 - accuracy: 0.9435 - val_loss: 0.5179 - val_accuracy: 0.8611\n",
      "Epoch 9/20\n",
      "46/46 - 1032s - loss: 0.1666 - accuracy: 0.9421 - val_loss: 0.4121 - val_accuracy: 0.8806\n",
      "12/12 [==============================] - 16s 1s/step - loss: 0.3437 - accuracy: 0.9056\n",
      "INFO:tensorflow:Assets written to: saved_models/Model_Female/Run-6/assets\n",
      "--- Starting trial: run-7\n",
      "{'filter_size_1': 5, 'filters_number': 64, 'filter_size_2': 3, 'dense_size': 256}\n",
      "Epoch 1/20\n",
      "46/46 - 114s - loss: 1.5081 - accuracy: 0.4976 - val_loss: 1.1338 - val_accuracy: 0.5639\n",
      "Epoch 2/20\n",
      "46/46 - 118s - loss: 0.6283 - accuracy: 0.7827 - val_loss: 0.4896 - val_accuracy: 0.8639\n",
      "Epoch 3/20\n",
      "46/46 - 112s - loss: 0.5152 - accuracy: 0.8326 - val_loss: 0.5499 - val_accuracy: 0.8139\n",
      "Epoch 4/20\n",
      "46/46 - 119s - loss: 0.3861 - accuracy: 0.8718 - val_loss: 0.4436 - val_accuracy: 0.8583\n",
      "Epoch 5/20\n",
      "46/46 - 124s - loss: 0.3096 - accuracy: 0.8919 - val_loss: 0.4017 - val_accuracy: 0.8778\n",
      "Epoch 6/20\n",
      "46/46 - 122s - loss: 0.2605 - accuracy: 0.9075 - val_loss: 0.4551 - val_accuracy: 0.8750\n",
      "Epoch 7/20\n",
      "46/46 - 105s - loss: 0.2174 - accuracy: 0.9293 - val_loss: 0.4606 - val_accuracy: 0.8806\n",
      "12/12 [==============================] - 4s 316ms/step - loss: 0.4017 - accuracy: 0.8778\n",
      "INFO:tensorflow:Assets written to: saved_models/Model_Female/Run-7/assets\n",
      "--- Starting trial: run-8\n",
      "{'filter_size_1': 5, 'filters_number': 64, 'filter_size_2': 5, 'dense_size': 256}\n",
      "Epoch 1/20\n",
      "46/46 - 204s - loss: 1.4118 - accuracy: 0.5139 - val_loss: 0.6870 - val_accuracy: 0.7806\n",
      "Epoch 2/20\n",
      "46/46 - 165s - loss: 0.6430 - accuracy: 0.7907 - val_loss: 0.5756 - val_accuracy: 0.8278\n",
      "Epoch 3/20\n",
      "46/46 - 172s - loss: 0.4937 - accuracy: 0.8392 - val_loss: 0.5155 - val_accuracy: 0.8222\n",
      "Epoch 4/20\n",
      "46/46 - 159s - loss: 0.4318 - accuracy: 0.8565 - val_loss: 0.5097 - val_accuracy: 0.8278\n",
      "Epoch 5/20\n",
      "46/46 - 193s - loss: 0.4267 - accuracy: 0.8579 - val_loss: 0.5098 - val_accuracy: 0.8444\n",
      "Epoch 6/20\n",
      "46/46 - 208s - loss: 0.3915 - accuracy: 0.8659 - val_loss: 0.5867 - val_accuracy: 0.8111\n",
      "12/12 [==============================] - 9s 659ms/step - loss: 0.5097 - accuracy: 0.8278\n",
      "INFO:tensorflow:Assets written to: saved_models/Model_Female/Run-8/assets\n",
      "--- Starting trial: run-9\n",
      "{'filter_size_1': 5, 'filters_number': 96, 'filter_size_2': 3, 'dense_size': 256}\n",
      "Epoch 1/20\n",
      "46/46 - 194s - loss: 1.4962 - accuracy: 0.4920 - val_loss: 0.7489 - val_accuracy: 0.7389\n",
      "Epoch 2/20\n",
      "46/46 - 187s - loss: 0.6053 - accuracy: 0.7883 - val_loss: 0.6595 - val_accuracy: 0.7528\n",
      "Epoch 3/20\n",
      "46/46 - 157s - loss: 0.4813 - accuracy: 0.8319 - val_loss: 0.4695 - val_accuracy: 0.8528\n",
      "Epoch 4/20\n",
      "46/46 - 190s - loss: 0.4080 - accuracy: 0.8621 - val_loss: 0.5083 - val_accuracy: 0.8111\n",
      "Epoch 5/20\n",
      "46/46 - 175s - loss: 0.3709 - accuracy: 0.8791 - val_loss: 0.4567 - val_accuracy: 0.8667\n",
      "Epoch 6/20\n",
      "46/46 - 185s - loss: 0.2580 - accuracy: 0.9144 - val_loss: 0.4942 - val_accuracy: 0.8611\n",
      "Epoch 7/20\n",
      "46/46 - 146s - loss: 0.2748 - accuracy: 0.9109 - val_loss: 0.4844 - val_accuracy: 0.8528\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 5s 394ms/step - loss: 0.4567 - accuracy: 0.8667\n",
      "INFO:tensorflow:Assets written to: saved_models/Model_Female/Run-9/assets\n",
      "--- Starting trial: run-10\n",
      "{'filter_size_1': 5, 'filters_number': 96, 'filter_size_2': 5, 'dense_size': 256}\n",
      "Epoch 1/20\n",
      "46/46 - 256s - loss: 1.2859 - accuracy: 0.5596 - val_loss: 0.6587 - val_accuracy: 0.7833\n",
      "Epoch 2/20\n",
      "46/46 - 2868s - loss: 0.7076 - accuracy: 0.7751 - val_loss: 0.6640 - val_accuracy: 0.8028\n",
      "Epoch 3/20\n",
      "46/46 - 356s - loss: 0.5107 - accuracy: 0.8222 - val_loss: 0.9028 - val_accuracy: 0.6972\n",
      "12/12 [==============================] - 12s 985ms/step - loss: 0.6587 - accuracy: 0.7833\n",
      "INFO:tensorflow:Assets written to: saved_models/Model_Female/Run-10/assets\n",
      "--- Starting trial: run-11\n",
      "{'filter_size_1': 5, 'filters_number': 128, 'filter_size_2': 3, 'dense_size': 256}\n",
      "Epoch 1/20\n",
      "46/46 - 338s - loss: 1.9291 - accuracy: 0.4238 - val_loss: 0.7489 - val_accuracy: 0.7333\n",
      "Epoch 2/20\n",
      "46/46 - 276s - loss: 0.6933 - accuracy: 0.7568 - val_loss: 0.6456 - val_accuracy: 0.7667\n",
      "Epoch 3/20\n",
      "46/46 - 262s - loss: 0.5237 - accuracy: 0.8257 - val_loss: 0.5239 - val_accuracy: 0.8306\n",
      "Epoch 4/20\n",
      "46/46 - 256s - loss: 0.4933 - accuracy: 0.8399 - val_loss: 0.5115 - val_accuracy: 0.8556\n",
      "Epoch 5/20\n",
      "46/46 - 266s - loss: 0.3940 - accuracy: 0.8680 - val_loss: 0.4685 - val_accuracy: 0.8694\n",
      "Epoch 6/20\n",
      "46/46 - 268s - loss: 0.3156 - accuracy: 0.8957 - val_loss: 0.4693 - val_accuracy: 0.8694\n",
      "Epoch 7/20\n",
      "46/46 - 304s - loss: 0.2551 - accuracy: 0.9130 - val_loss: 0.5118 - val_accuracy: 0.8639\n",
      "12/12 [==============================] - 10s 787ms/step - loss: 0.4685 - accuracy: 0.8694\n",
      "INFO:tensorflow:Assets written to: saved_models/Model_Female/Run-11/assets\n",
      "--- Starting trial: run-12\n",
      "{'filter_size_1': 5, 'filters_number': 128, 'filter_size_2': 5, 'dense_size': 256}\n",
      "Epoch 1/20\n",
      "46/46 - 483s - loss: 1.6271 - accuracy: 0.4775 - val_loss: 0.7409 - val_accuracy: 0.7556\n",
      "Epoch 2/20\n",
      "46/46 - 464s - loss: 0.6521 - accuracy: 0.7789 - val_loss: 0.5957 - val_accuracy: 0.8000\n",
      "Epoch 3/20\n",
      "46/46 - 516s - loss: 0.5152 - accuracy: 0.8316 - val_loss: 0.6208 - val_accuracy: 0.8028\n",
      "Epoch 4/20\n",
      "46/46 - 548s - loss: 0.4120 - accuracy: 0.8635 - val_loss: 0.4553 - val_accuracy: 0.8611\n",
      "Epoch 5/20\n",
      "46/46 - 529s - loss: 0.3470 - accuracy: 0.8836 - val_loss: 0.4541 - val_accuracy: 0.8417\n",
      "Epoch 6/20\n",
      "46/46 - 470s - loss: 0.2561 - accuracy: 0.9137 - val_loss: 0.4932 - val_accuracy: 0.8472\n",
      "Epoch 7/20\n",
      "46/46 - 482s - loss: 0.2217 - accuracy: 0.9213 - val_loss: 0.4299 - val_accuracy: 0.8861\n",
      "Epoch 8/20\n",
      "46/46 - 517s - loss: 0.1803 - accuracy: 0.9380 - val_loss: 0.4377 - val_accuracy: 0.8944\n",
      "Epoch 9/20\n",
      "46/46 - 261s - loss: 0.1284 - accuracy: 0.9539 - val_loss: 0.3949 - val_accuracy: 0.8944\n",
      "Epoch 10/20\n",
      "46/46 - 260s - loss: 0.1176 - accuracy: 0.9605 - val_loss: 0.4148 - val_accuracy: 0.8972\n",
      "Epoch 11/20\n",
      "46/46 - 223s - loss: 0.1082 - accuracy: 0.9612 - val_loss: 0.5024 - val_accuracy: 0.8667\n",
      "12/12 [==============================] - 9s 693ms/step - loss: 0.3949 - accuracy: 0.8944\n",
      "INFO:tensorflow:Assets written to: saved_models/Model_Female/Run-12/assets\n",
      "--- Starting trial: run-13\n",
      "{'filter_size_1': 7, 'filters_number': 64, 'filter_size_2': 3, 'dense_size': 256}\n",
      "Epoch 1/20\n",
      "46/46 - 71s - loss: 1.5008 - accuracy: 0.4255 - val_loss: 1.2528 - val_accuracy: 0.4861\n",
      "Epoch 2/20\n",
      "46/46 - 67s - loss: 0.7783 - accuracy: 0.7159 - val_loss: 0.6374 - val_accuracy: 0.7889\n",
      "Epoch 3/20\n",
      "46/46 - 66s - loss: 0.5405 - accuracy: 0.8153 - val_loss: 0.5107 - val_accuracy: 0.8389\n",
      "Epoch 4/20\n",
      "46/46 - 66s - loss: 0.4526 - accuracy: 0.8507 - val_loss: 0.6115 - val_accuracy: 0.7667\n",
      "Epoch 5/20\n",
      "46/46 - 68s - loss: 0.4149 - accuracy: 0.8617 - val_loss: 0.3770 - val_accuracy: 0.8917\n",
      "Epoch 6/20\n",
      "46/46 - 67s - loss: 0.3089 - accuracy: 0.8919 - val_loss: 0.4995 - val_accuracy: 0.8278\n",
      "Epoch 7/20\n",
      "46/46 - 65s - loss: 0.3105 - accuracy: 0.8926 - val_loss: 0.9087 - val_accuracy: 0.7444\n",
      "12/12 [==============================] - 2s 160ms/step - loss: 0.3770 - accuracy: 0.8917\n",
      "INFO:tensorflow:Assets written to: saved_models/Model_Female/Run-13/assets\n",
      "--- Starting trial: run-14\n",
      "{'filter_size_1': 7, 'filters_number': 64, 'filter_size_2': 5, 'dense_size': 256}\n",
      "Epoch 1/20\n",
      "46/46 - 93s - loss: 1.4825 - accuracy: 0.4380 - val_loss: 0.8900 - val_accuracy: 0.6472\n",
      "Epoch 2/20\n",
      "46/46 - 85s - loss: 0.7280 - accuracy: 0.7491 - val_loss: 0.5339 - val_accuracy: 0.8306\n",
      "Epoch 3/20\n",
      "46/46 - 91s - loss: 0.4966 - accuracy: 0.8302 - val_loss: 0.4394 - val_accuracy: 0.8528\n",
      "Epoch 4/20\n",
      "46/46 - 91s - loss: 0.4225 - accuracy: 0.8624 - val_loss: 0.5199 - val_accuracy: 0.8639\n",
      "Epoch 5/20\n",
      "46/46 - 95s - loss: 0.3570 - accuracy: 0.8829 - val_loss: 0.4237 - val_accuracy: 0.8750\n",
      "Epoch 6/20\n",
      "46/46 - 96s - loss: 0.2889 - accuracy: 0.8978 - val_loss: 0.4542 - val_accuracy: 0.8667\n",
      "Epoch 7/20\n",
      "46/46 - 81s - loss: 0.2247 - accuracy: 0.9238 - val_loss: 0.4486 - val_accuracy: 0.8806\n",
      "12/12 [==============================] - 2s 199ms/step - loss: 0.4237 - accuracy: 0.8750\n",
      "INFO:tensorflow:Assets written to: saved_models/Model_Female/Run-14/assets\n",
      "--- Starting trial: run-15\n",
      "{'filter_size_1': 7, 'filters_number': 96, 'filter_size_2': 3, 'dense_size': 256}\n",
      "Epoch 1/20\n",
      "46/46 - 102s - loss: 1.4991 - accuracy: 0.4442 - val_loss: 0.8930 - val_accuracy: 0.7167\n",
      "Epoch 2/20\n",
      "46/46 - 97s - loss: 0.7142 - accuracy: 0.7529 - val_loss: 0.5713 - val_accuracy: 0.8139\n",
      "Epoch 3/20\n",
      "46/46 - 97s - loss: 0.5185 - accuracy: 0.8299 - val_loss: 0.4867 - val_accuracy: 0.8500\n",
      "Epoch 4/20\n",
      "46/46 - 87s - loss: 0.3897 - accuracy: 0.8656 - val_loss: 0.4693 - val_accuracy: 0.8611\n",
      "Epoch 5/20\n",
      "46/46 - 81s - loss: 0.3236 - accuracy: 0.8902 - val_loss: 0.4489 - val_accuracy: 0.8667\n",
      "Epoch 6/20\n",
      "46/46 - 131s - loss: 0.2670 - accuracy: 0.9040 - val_loss: 0.4000 - val_accuracy: 0.8722\n",
      "Epoch 7/20\n",
      "46/46 - 105s - loss: 0.2341 - accuracy: 0.9241 - val_loss: 0.4762 - val_accuracy: 0.8722\n",
      "Epoch 8/20\n",
      "46/46 - 96s - loss: 0.1999 - accuracy: 0.9338 - val_loss: 0.3966 - val_accuracy: 0.8917\n",
      "Epoch 9/20\n",
      "46/46 - 102s - loss: 0.1615 - accuracy: 0.9446 - val_loss: 0.4424 - val_accuracy: 0.8944\n",
      "Epoch 10/20\n",
      "46/46 - 102s - loss: 0.1341 - accuracy: 0.9553 - val_loss: 0.4157 - val_accuracy: 0.9000\n",
      "12/12 [==============================] - 5s 389ms/step - loss: 0.3966 - accuracy: 0.8917\n",
      "INFO:tensorflow:Assets written to: saved_models/Model_Female/Run-15/assets\n",
      "--- Starting trial: run-16\n",
      "{'filter_size_1': 7, 'filters_number': 96, 'filter_size_2': 5, 'dense_size': 256}\n",
      "Epoch 1/20\n",
      "46/46 - 211s - loss: 1.4280 - accuracy: 0.4875 - val_loss: 0.9776 - val_accuracy: 0.6417\n",
      "Epoch 2/20\n",
      "46/46 - 163s - loss: 0.7561 - accuracy: 0.7401 - val_loss: 0.5512 - val_accuracy: 0.8444\n",
      "Epoch 3/20\n",
      "46/46 - 161s - loss: 0.5369 - accuracy: 0.8243 - val_loss: 0.5107 - val_accuracy: 0.8417\n",
      "Epoch 4/20\n",
      "46/46 - 163s - loss: 0.4240 - accuracy: 0.8579 - val_loss: 0.4637 - val_accuracy: 0.8611\n",
      "Epoch 5/20\n",
      "46/46 - 287s - loss: 0.3879 - accuracy: 0.8818 - val_loss: 0.5057 - val_accuracy: 0.8667\n",
      "Epoch 6/20\n",
      "46/46 - 272s - loss: 0.3799 - accuracy: 0.8770 - val_loss: 0.5789 - val_accuracy: 0.8361\n",
      "12/12 [==============================] - 10s 822ms/step - loss: 0.4637 - accuracy: 0.8611\n",
      "INFO:tensorflow:Assets written to: saved_models/Model_Female/Run-16/assets\n",
      "--- Starting trial: run-17\n",
      "{'filter_size_1': 7, 'filters_number': 128, 'filter_size_2': 3, 'dense_size': 256}\n",
      "Epoch 1/20\n",
      "46/46 - 302s - loss: 1.7179 - accuracy: 0.3940 - val_loss: 1.0821 - val_accuracy: 0.6167\n",
      "Epoch 2/20\n",
      "46/46 - 362s - loss: 0.7829 - accuracy: 0.7266 - val_loss: 0.9130 - val_accuracy: 0.6556\n",
      "Epoch 3/20\n",
      "46/46 - 336s - loss: 0.5983 - accuracy: 0.8067 - val_loss: 0.5830 - val_accuracy: 0.8139\n",
      "Epoch 4/20\n",
      "46/46 - 372s - loss: 0.4359 - accuracy: 0.8541 - val_loss: 0.5037 - val_accuracy: 0.8444\n",
      "Epoch 5/20\n",
      "46/46 - 377s - loss: 0.3501 - accuracy: 0.8808 - val_loss: 0.6709 - val_accuracy: 0.7833\n",
      "Epoch 6/20\n",
      "46/46 - 350s - loss: 0.3594 - accuracy: 0.8770 - val_loss: 0.4397 - val_accuracy: 0.8611\n",
      "Epoch 7/20\n",
      "46/46 - 336s - loss: 0.2794 - accuracy: 0.9012 - val_loss: 0.4996 - val_accuracy: 0.8306\n",
      "Epoch 8/20\n",
      "46/46 - 333s - loss: 0.2028 - accuracy: 0.9317 - val_loss: 0.5079 - val_accuracy: 0.8444\n",
      "12/12 [==============================] - 11s 916ms/step - loss: 0.4397 - accuracy: 0.8611\n",
      "INFO:tensorflow:Assets written to: saved_models/Model_Female/Run-17/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting trial: run-18\n",
      "{'filter_size_1': 7, 'filters_number': 128, 'filter_size_2': 5, 'dense_size': 256}\n",
      "Epoch 1/20\n",
      "46/46 - 697s - loss: 1.9916 - accuracy: 0.3732 - val_loss: 1.1543 - val_accuracy: 0.5139\n",
      "Epoch 2/20\n",
      "46/46 - 556s - loss: 0.8081 - accuracy: 0.7225 - val_loss: 0.9166 - val_accuracy: 0.6306\n",
      "Epoch 3/20\n",
      "46/46 - 622s - loss: 0.6073 - accuracy: 0.7814 - val_loss: 0.5396 - val_accuracy: 0.8306\n",
      "Epoch 4/20\n",
      "46/46 - 566s - loss: 0.4821 - accuracy: 0.8365 - val_loss: 0.4810 - val_accuracy: 0.8722\n",
      "Epoch 5/20\n",
      "46/46 - 555s - loss: 0.3719 - accuracy: 0.8687 - val_loss: 0.4289 - val_accuracy: 0.8694\n",
      "Epoch 6/20\n",
      "46/46 - 500s - loss: 0.3141 - accuracy: 0.8957 - val_loss: 0.4867 - val_accuracy: 0.8639\n",
      "Epoch 7/20\n",
      "46/46 - 3093s - loss: 0.2874 - accuracy: 0.9044 - val_loss: 0.4532 - val_accuracy: 0.8694\n",
      "12/12 [==============================] - 12s 992ms/step - loss: 0.4289 - accuracy: 0.8694\n",
      "INFO:tensorflow:Assets written to: saved_models/Model_Female/Run-18/assets\n"
     ]
    }
   ],
   "source": [
    "session_num = 1\n",
    "\n",
    "for filter_size_1 in HP_FILTER_SIZE_1.domain.values:\n",
    "    for filter_num in HP_FILTER_NUM.domain.values:\n",
    "        for filter_size_2 in HP_FILTER_SIZE_2.domain.values:\n",
    "            for dense_size in HP_DENSE_SIZE.domain.values:\n",
    "            \n",
    "                hparams = {\n",
    "                    HP_FILTER_SIZE_1: filter_size_1,\n",
    "                    HP_FILTER_NUM: filter_num,\n",
    "                    HP_FILTER_SIZE_2: filter_size_2,\n",
    "                    HP_DENSE_SIZE: dense_size\n",
    "                }\n",
    "\n",
    "                run_name = \"run-%d\" % session_num\n",
    "                print('--- Starting trial: %s' % run_name)\n",
    "                print({h.name: hparams[h] for h in hparams})\n",
    "                run('Logs/Model_Female/hparam_tuning/' + run_name, hparams, session_num)\n",
    "\n",
    "                session_num += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading a model to evaluate on the test set\n",
    "model = tf.keras.models.load_model(r\"saved_models/Model_Female/Run-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 4s 242ms/step - loss: 0.5377 - accuracy: 0.8194\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(images_test,labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.5377. Test accuracy: 81.94%\n"
     ]
    }
   ],
   "source": [
    "# Printing the test results\n",
    "print('Test loss: {0:.4f}. Test accuracy: {1:.2f}%'.format(test_loss, test_accuracy*100.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir \"Logs/Model_Female/hparam_tuning\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir \"Logs/Model_Female/fit\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
