{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import itertools\n",
    "\n",
    "import numpy as np\n",
    "import sklearn.metrics\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorboard.plugins.hparams import api as hp\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the datasets\n",
    "data_train = np.load(r\"Dataset/Shoes - Male - Train.npz\")\n",
    "data_val = np.load(r\"Dataset/Shoes - Male - Validation.npz\")\n",
    "data_test = np.load(r\"Dataset/Shoes - Male - Test.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting the arrays from the imported data\n",
    "images_train = data_train['images']\n",
    "labels_train = data_train['labels']\n",
    "\n",
    "images_val = data_val['images']\n",
    "labels_val = data_val['labels']\n",
    "\n",
    "images_test = data_test['images']\n",
    "labels_test = data_test['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling the pixel values of all images\n",
    "images_train = images_train/255.0\n",
    "images_val = images_val/255.0\n",
    "images_test = images_test/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the hyperparameters we would tune, and their values to be tested\n",
    "HP_FILTER_SIZE_1 = hp.HParam('filter_size_1', hp.Discrete([3,5,7]))\n",
    "HP_FILTER_NUM = hp.HParam('filters_number', hp.Discrete([64,96,128]))\n",
    "HP_FILTER_SIZE_2 = hp.HParam('filter_size_2', hp.Discrete([3,5]))\n",
    "HP_DENSE_SIZE = hp.HParam('dense_size', hp.Discrete([256]))#,512,1024]))\n",
    "\n",
    "METRIC_ACCURACY = 'accuracy'\n",
    "\n",
    "# Logging setup info\n",
    "with tf.summary.create_file_writer(r'Logs/Model_Male/hparam_tuning/').as_default():\n",
    "    hp.hparams_config(\n",
    "        hparams=[HP_FILTER_SIZE_1, HP_FILTER_NUM, HP_FILTER_SIZE_2, HP_DENSE_SIZE],\n",
    "        metrics=[hp.Metric(METRIC_ACCURACY, display_name='Accuracy')],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 20\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrapping our model and training in a function\n",
    "def train_test_model(hparams, session_num):\n",
    "    \n",
    "    # Outlining the model/architecture of our CNN\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Conv2D(hparams[HP_FILTER_NUM], hparams[HP_FILTER_SIZE_1], activation='relu', input_shape=(120,90,3)),\n",
    "        tf.keras.layers.MaxPooling2D(pool_size=(2,2)),\n",
    "        tf.keras.layers.Conv2D(hparams[HP_FILTER_NUM], hparams[HP_FILTER_SIZE_2], activation='relu'),\n",
    "        tf.keras.layers.MaxPooling2D(pool_size=(2,2)),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(hparams[HP_DENSE_SIZE], activation='relu'),\n",
    "        tf.keras.layers.Dense(5)\n",
    "    ])\n",
    "    \n",
    "    # Defining the loss function\n",
    "    loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "    # Compiling the model\n",
    "    model.compile(optimizer='adam', loss=loss_fn, metrics=['accuracy'])\n",
    "    \n",
    "    # Defining the logging directory\n",
    "    log_dir = \"Logs/Model_Male/fit/\" + \"run-{}\".format(session_num)\n",
    "    \n",
    "    def plot_confusion_matrix(cm, class_names):\n",
    "        \"\"\"\n",
    "        Returns a matplotlib figure containing the plotted confusion matrix.\n",
    "\n",
    "        Args:\n",
    "          cm (array, shape = [n, n]): a confusion matrix of integer classes\n",
    "          class_names (array, shape = [n]): String names of the integer classes\n",
    "        \"\"\"\n",
    "        figure = plt.figure(figsize=(12, 12))\n",
    "        plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "        plt.title(\"Confusion matrix\")\n",
    "        plt.colorbar()\n",
    "        tick_marks = np.arange(len(class_names))\n",
    "        plt.xticks(tick_marks, class_names, rotation=45)\n",
    "        plt.yticks(tick_marks, class_names)\n",
    "\n",
    "        # Normalize the confusion matrix.\n",
    "        cm = np.around(cm.astype('float') / cm.sum(axis=1)[:, np.newaxis], decimals=2)\n",
    "\n",
    "        # Use white text if squares are dark; otherwise black.\n",
    "        threshold = cm.max() / 2.\n",
    "        for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "            color = \"white\" if cm[i, j] > threshold else \"black\"\n",
    "            plt.text(j, i, cm[i, j], horizontalalignment=\"center\", color=color)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.ylabel('True label')\n",
    "        plt.xlabel('Predicted label')\n",
    "        return figure  \n",
    "    \n",
    "    \n",
    "    def plot_to_image(figure):\n",
    "        \"\"\"Converts the matplotlib plot specified by 'figure' to a PNG image and\n",
    "        returns it. The supplied figure is closed and inaccessible after this call.\"\"\"\n",
    "        # Save the plot to a PNG in memory.\n",
    "        buf = io.BytesIO()\n",
    "        plt.savefig(buf, format='png')\n",
    "        # Closing the figure prevents it from being displayed directly inside\n",
    "        # the notebook.\n",
    "        plt.close(figure)\n",
    "        buf.seek(0)\n",
    "        # Convert PNG buffer to TF image\n",
    "        image = tf.image.decode_png(buf.getvalue(), channels=4)\n",
    "        # Add the batch dimension\n",
    "        image = tf.expand_dims(image, 0)\n",
    "        return image\n",
    "    \n",
    "    \n",
    "    # Defining a file writer for Confusion Matrix logging purposes\n",
    "    file_writer_cm = tf.summary.create_file_writer(log_dir + '/cm')\n",
    "    \n",
    "    \n",
    "    def log_confusion_matrix(epoch, logs):\n",
    "        # Use the model to predict the values from the validation dataset.\n",
    "        test_pred_raw = model.predict(images_val)\n",
    "        test_pred = np.argmax(test_pred_raw, axis=1)\n",
    "\n",
    "        # Calculate the confusion matrix.\n",
    "        cm = sklearn.metrics.confusion_matrix(labels_val, test_pred)\n",
    "        # Log the confusion matrix as an image summary.\n",
    "        figure = plot_confusion_matrix(cm, class_names=['Boots','Trainers/Sneakers', 'Sandals/Flip flops/Slippers', 'Formal shoes', 'Others'])\n",
    "        cm_image = plot_to_image(figure)\n",
    "\n",
    "        # Log the confusion matrix as an image summary.\n",
    "        with file_writer_cm.as_default():\n",
    "            tf.summary.image(\"Confusion Matrix\", cm_image, step=epoch)\n",
    "    \n",
    "    \n",
    "    # Define the Tensorboard and Confusion Matrix callbacks.\n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1, profile_batch=0)\n",
    "    cm_callback = tf.keras.callbacks.LambdaCallback(on_epoch_end=log_confusion_matrix)\n",
    "\n",
    "    \n",
    "    # Defining early stopping to prevent overfitting\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "        monitor = 'val_loss',\n",
    "        mode = 'auto',\n",
    "        min_delta = 0,\n",
    "        patience = 2,\n",
    "        verbose = 0, \n",
    "        restore_best_weights = True\n",
    "    )\n",
    "    \n",
    "    # Training the model\n",
    "    model.fit(\n",
    "        images_train,\n",
    "        labels_train,\n",
    "        epochs = EPOCHS,\n",
    "        batch_size = BATCH_SIZE,\n",
    "        callbacks = [tensorboard_callback, cm_callback, early_stopping],\n",
    "        validation_data = (images_val,labels_val),\n",
    "        verbose = 2\n",
    "    )\n",
    "    \n",
    "    \n",
    "    # Evaluating the model's performance on the validation set\n",
    "    _, accuracy = model.evaluate(images_val,labels_val)\n",
    "    \n",
    "    # Saving the current model for future reference\n",
    "    model.save(r\"saved_models/Model_Male/Run-{}\".format(session_num))\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a function to log the resuls\n",
    "def run(log_dir, hparams, session_num):\n",
    "    \n",
    "    with tf.summary.create_file_writer(log_dir).as_default():\n",
    "        hp.hparams(hparams)  # record the values used in this trial\n",
    "        accuracy = train_test_model(hparams, session_num)\n",
    "        tf.summary.scalar(METRIC_ACCURACY, accuracy, step=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting trial: run-1\n",
      "{'filter_size_1': 3, 'filters_number': 64, 'filter_size_2': 3, 'dense_size': 256}\n",
      "Epoch 1/20\n",
      "33/33 - 34s - loss: 1.7621 - accuracy: 0.4959 - val_loss: 0.6434 - val_accuracy: 0.7529\n",
      "Epoch 2/20\n",
      "33/33 - 33s - loss: 0.6105 - accuracy: 0.7829 - val_loss: 0.4770 - val_accuracy: 0.8378\n",
      "Epoch 3/20\n",
      "33/33 - 33s - loss: 0.4548 - accuracy: 0.8292 - val_loss: 0.4330 - val_accuracy: 0.8494\n",
      "Epoch 4/20\n",
      "33/33 - 41s - loss: 0.3822 - accuracy: 0.8625 - val_loss: 0.3608 - val_accuracy: 0.8571\n",
      "Epoch 5/20\n",
      "33/33 - 35s - loss: 0.3495 - accuracy: 0.8799 - val_loss: 0.3215 - val_accuracy: 0.8919\n",
      "Epoch 6/20\n",
      "33/33 - 35s - loss: 0.2754 - accuracy: 0.9030 - val_loss: 0.3236 - val_accuracy: 0.8803\n",
      "Epoch 7/20\n",
      "33/33 - 34s - loss: 0.2590 - accuracy: 0.9088 - val_loss: 0.3444 - val_accuracy: 0.8803\n",
      "9/9 [==============================] - 1s 105ms/step - loss: 0.3215 - accuracy: 0.8919\n",
      "INFO:tensorflow:Assets written to: saved_models/Model_Male/Run-1/assets\n",
      "--- Starting trial: run-2\n",
      "{'filter_size_1': 3, 'filters_number': 64, 'filter_size_2': 5, 'dense_size': 256}\n",
      "Epoch 1/20\n",
      "33/33 - 57s - loss: 1.0363 - accuracy: 0.6261 - val_loss: 0.6159 - val_accuracy: 0.7645\n",
      "Epoch 2/20\n",
      "33/33 - 71s - loss: 0.5173 - accuracy: 0.8085 - val_loss: 0.4552 - val_accuracy: 0.8263\n",
      "Epoch 3/20\n",
      "33/33 - 59s - loss: 0.4241 - accuracy: 0.8509 - val_loss: 0.4002 - val_accuracy: 0.8533\n",
      "Epoch 4/20\n",
      "33/33 - 52s - loss: 0.3582 - accuracy: 0.8780 - val_loss: 0.3663 - val_accuracy: 0.8726\n",
      "Epoch 5/20\n",
      "33/33 - 54s - loss: 0.2952 - accuracy: 0.8862 - val_loss: 0.3792 - val_accuracy: 0.8494\n",
      "Epoch 6/20\n",
      "33/33 - 54s - loss: 0.2614 - accuracy: 0.9045 - val_loss: 0.3263 - val_accuracy: 0.8803\n",
      "Epoch 7/20\n",
      "33/33 - 54s - loss: 0.1923 - accuracy: 0.9329 - val_loss: 0.4247 - val_accuracy: 0.8533\n",
      "Epoch 8/20\n",
      "33/33 - 55s - loss: 0.1906 - accuracy: 0.9276 - val_loss: 0.3829 - val_accuracy: 0.8764\n",
      "9/9 [==============================] - 2s 183ms/step - loss: 0.3263 - accuracy: 0.8803\n",
      "INFO:tensorflow:Assets written to: saved_models/Model_Male/Run-2/assets\n",
      "--- Starting trial: run-3\n",
      "{'filter_size_1': 3, 'filters_number': 96, 'filter_size_2': 3, 'dense_size': 256}\n",
      "Epoch 1/20\n",
      "33/33 - 54s - loss: 1.3445 - accuracy: 0.5769 - val_loss: 0.5742 - val_accuracy: 0.7954\n",
      "Epoch 2/20\n",
      "33/33 - 54s - loss: 0.5302 - accuracy: 0.7959 - val_loss: 0.4699 - val_accuracy: 0.8456\n",
      "Epoch 3/20\n",
      "33/33 - 60s - loss: 0.4625 - accuracy: 0.8379 - val_loss: 0.4080 - val_accuracy: 0.8185\n",
      "Epoch 4/20\n",
      "33/33 - 70s - loss: 0.3684 - accuracy: 0.8606 - val_loss: 0.3355 - val_accuracy: 0.8610\n",
      "Epoch 5/20\n",
      "33/33 - 65s - loss: 0.3090 - accuracy: 0.8862 - val_loss: 0.3395 - val_accuracy: 0.8842\n",
      "Epoch 6/20\n",
      "33/33 - 61s - loss: 0.2574 - accuracy: 0.9011 - val_loss: 0.3549 - val_accuracy: 0.8687\n",
      "9/9 [==============================] - 2s 208ms/step - loss: 0.3355 - accuracy: 0.8610\n",
      "INFO:tensorflow:Assets written to: saved_models/Model_Male/Run-3/assets\n",
      "--- Starting trial: run-4\n",
      "{'filter_size_1': 3, 'filters_number': 96, 'filter_size_2': 5, 'dense_size': 256}\n",
      "Epoch 1/20\n",
      "33/33 - 107s - loss: 1.3695 - accuracy: 0.5794 - val_loss: 0.5713 - val_accuracy: 0.7954\n",
      "Epoch 2/20\n",
      "33/33 - 99s - loss: 0.5659 - accuracy: 0.7964 - val_loss: 0.4436 - val_accuracy: 0.8301\n",
      "Epoch 3/20\n",
      "33/33 - 107s - loss: 0.4477 - accuracy: 0.8398 - val_loss: 0.4583 - val_accuracy: 0.8224\n",
      "Epoch 4/20\n",
      "33/33 - 99s - loss: 0.4098 - accuracy: 0.8452 - val_loss: 0.3686 - val_accuracy: 0.8417\n",
      "Epoch 5/20\n",
      "33/33 - 107s - loss: 0.3458 - accuracy: 0.8755 - val_loss: 0.3660 - val_accuracy: 0.8533\n",
      "Epoch 6/20\n",
      "33/33 - 101s - loss: 0.2891 - accuracy: 0.8915 - val_loss: 0.3302 - val_accuracy: 0.8842\n",
      "Epoch 7/20\n",
      "33/33 - 100s - loss: 0.2926 - accuracy: 0.8881 - val_loss: 0.4035 - val_accuracy: 0.8610\n",
      "Epoch 8/20\n",
      "33/33 - 98s - loss: 0.2423 - accuracy: 0.9180 - val_loss: 0.3288 - val_accuracy: 0.8842\n",
      "Epoch 9/20\n",
      "33/33 - 106s - loss: 0.2014 - accuracy: 0.9262 - val_loss: 0.3619 - val_accuracy: 0.8842\n",
      "Epoch 10/20\n",
      "33/33 - 96s - loss: 0.1757 - accuracy: 0.9334 - val_loss: 0.3709 - val_accuracy: 0.8803\n",
      "9/9 [==============================] - 3s 336ms/step - loss: 0.3288 - accuracy: 0.8842\n",
      "INFO:tensorflow:Assets written to: saved_models/Model_Male/Run-4/assets\n",
      "--- Starting trial: run-5\n",
      "{'filter_size_1': 3, 'filters_number': 128, 'filter_size_2': 3, 'dense_size': 256}\n",
      "Epoch 1/20\n",
      "33/33 - 83s - loss: 1.4885 - accuracy: 0.5678 - val_loss: 0.5681 - val_accuracy: 0.8147\n",
      "Epoch 2/20\n",
      "33/33 - 81s - loss: 0.5678 - accuracy: 0.7964 - val_loss: 0.4628 - val_accuracy: 0.8301\n",
      "Epoch 3/20\n",
      "33/33 - 78s - loss: 0.4536 - accuracy: 0.8307 - val_loss: 0.4255 - val_accuracy: 0.8571\n",
      "Epoch 4/20\n",
      "33/33 - 81s - loss: 0.3855 - accuracy: 0.8611 - val_loss: 0.3529 - val_accuracy: 0.8571\n",
      "Epoch 5/20\n",
      "33/33 - 80s - loss: 0.3270 - accuracy: 0.8770 - val_loss: 0.3195 - val_accuracy: 0.8803\n",
      "Epoch 6/20\n",
      "33/33 - 84s - loss: 0.2700 - accuracy: 0.8982 - val_loss: 0.4016 - val_accuracy: 0.8571\n",
      "Epoch 7/20\n",
      "33/33 - 86s - loss: 0.2621 - accuracy: 0.9021 - val_loss: 0.3626 - val_accuracy: 0.8842\n",
      "9/9 [==============================] - 3s 320ms/step - loss: 0.3195 - accuracy: 0.8803\n",
      "INFO:tensorflow:Assets written to: saved_models/Model_Male/Run-5/assets\n",
      "--- Starting trial: run-6\n",
      "{'filter_size_1': 3, 'filters_number': 128, 'filter_size_2': 5, 'dense_size': 256}\n",
      "Epoch 1/20\n",
      "33/33 - 160s - loss: 1.4215 - accuracy: 0.5253 - val_loss: 0.5483 - val_accuracy: 0.8069\n",
      "Epoch 2/20\n",
      "33/33 - 182s - loss: 0.5924 - accuracy: 0.7902 - val_loss: 0.4870 - val_accuracy: 0.7954\n",
      "Epoch 3/20\n",
      "33/33 - 174s - loss: 0.5323 - accuracy: 0.8167 - val_loss: 0.3500 - val_accuracy: 0.8649\n",
      "Epoch 4/20\n",
      "33/33 - 970s - loss: 0.4573 - accuracy: 0.8466 - val_loss: 0.3632 - val_accuracy: 0.8571\n",
      "Epoch 5/20\n",
      "33/33 - 284s - loss: 0.3819 - accuracy: 0.8649 - val_loss: 0.3760 - val_accuracy: 0.8494\n",
      "9/9 [==============================] - 5s 520ms/step - loss: 0.3500 - accuracy: 0.8649\n",
      "INFO:tensorflow:Assets written to: saved_models/Model_Male/Run-6/assets\n",
      "--- Starting trial: run-7\n",
      "{'filter_size_1': 5, 'filters_number': 64, 'filter_size_2': 3, 'dense_size': 256}\n",
      "Epoch 1/20\n",
      "33/33 - 40s - loss: 1.3508 - accuracy: 0.5731 - val_loss: 0.5479 - val_accuracy: 0.7915\n",
      "Epoch 2/20\n",
      "33/33 - 37s - loss: 0.5667 - accuracy: 0.7969 - val_loss: 0.4706 - val_accuracy: 0.8301\n",
      "Epoch 3/20\n",
      "33/33 - 37s - loss: 0.4717 - accuracy: 0.8234 - val_loss: 0.5082 - val_accuracy: 0.8069\n",
      "Epoch 4/20\n",
      "33/33 - 46s - loss: 0.4221 - accuracy: 0.8442 - val_loss: 0.3796 - val_accuracy: 0.8571\n",
      "Epoch 5/20\n",
      "33/33 - 42s - loss: 0.3393 - accuracy: 0.8780 - val_loss: 0.3986 - val_accuracy: 0.8456\n",
      "Epoch 6/20\n",
      "33/33 - 47s - loss: 0.2947 - accuracy: 0.8900 - val_loss: 0.3624 - val_accuracy: 0.8610\n",
      "Epoch 7/20\n",
      "33/33 - 43s - loss: 0.2616 - accuracy: 0.9079 - val_loss: 0.3676 - val_accuracy: 0.8533\n",
      "Epoch 8/20\n",
      "33/33 - 36s - loss: 0.2327 - accuracy: 0.9146 - val_loss: 0.3383 - val_accuracy: 0.8842\n",
      "Epoch 9/20\n",
      "33/33 - 34s - loss: 0.2199 - accuracy: 0.9238 - val_loss: 0.4037 - val_accuracy: 0.8842\n",
      "Epoch 10/20\n",
      "33/33 - 36s - loss: 0.1861 - accuracy: 0.9392 - val_loss: 0.4304 - val_accuracy: 0.8533\n",
      "9/9 [==============================] - 1s 129ms/step - loss: 0.3383 - accuracy: 0.8842\n",
      "INFO:tensorflow:Assets written to: saved_models/Model_Male/Run-7/assets\n",
      "--- Starting trial: run-8\n",
      "{'filter_size_1': 5, 'filters_number': 64, 'filter_size_2': 5, 'dense_size': 256}\n",
      "Epoch 1/20\n",
      "33/33 - 75s - loss: 1.3710 - accuracy: 0.5861 - val_loss: 0.7612 - val_accuracy: 0.7336\n",
      "Epoch 2/20\n",
      "33/33 - 74s - loss: 0.6759 - accuracy: 0.7569 - val_loss: 0.5735 - val_accuracy: 0.7838\n",
      "Epoch 3/20\n",
      "33/33 - 76s - loss: 0.5173 - accuracy: 0.8070 - val_loss: 0.4489 - val_accuracy: 0.8533\n",
      "Epoch 4/20\n",
      "33/33 - 68s - loss: 0.4100 - accuracy: 0.8505 - val_loss: 0.3883 - val_accuracy: 0.8340\n",
      "Epoch 5/20\n",
      "33/33 - 59s - loss: 0.3960 - accuracy: 0.8616 - val_loss: 0.3739 - val_accuracy: 0.8533\n",
      "Epoch 6/20\n",
      "33/33 - 54s - loss: 0.3345 - accuracy: 0.8755 - val_loss: 0.4321 - val_accuracy: 0.8378\n",
      "Epoch 7/20\n",
      "33/33 - 53s - loss: 0.2911 - accuracy: 0.8958 - val_loss: 0.4799 - val_accuracy: 0.8301\n",
      "9/9 [==============================] - 2s 180ms/step - loss: 0.3739 - accuracy: 0.8533\n",
      "INFO:tensorflow:Assets written to: saved_models/Model_Male/Run-8/assets\n",
      "--- Starting trial: run-9\n",
      "{'filter_size_1': 5, 'filters_number': 96, 'filter_size_2': 3, 'dense_size': 256}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "33/33 - 57s - loss: 1.2528 - accuracy: 0.6170 - val_loss: 0.5970 - val_accuracy: 0.8185\n",
      "Epoch 2/20\n",
      "33/33 - 54s - loss: 0.5544 - accuracy: 0.7935 - val_loss: 0.5154 - val_accuracy: 0.8069\n",
      "Epoch 3/20\n",
      "33/33 - 64s - loss: 0.4472 - accuracy: 0.8427 - val_loss: 0.4109 - val_accuracy: 0.8301\n",
      "Epoch 4/20\n",
      "33/33 - 55s - loss: 0.4234 - accuracy: 0.8437 - val_loss: 0.4533 - val_accuracy: 0.8108\n",
      "Epoch 5/20\n",
      "33/33 - 53s - loss: 0.3491 - accuracy: 0.8760 - val_loss: 0.3504 - val_accuracy: 0.8687\n",
      "Epoch 6/20\n",
      "33/33 - 59s - loss: 0.2899 - accuracy: 0.8939 - val_loss: 0.3467 - val_accuracy: 0.8610\n",
      "Epoch 7/20\n",
      "33/33 - 60s - loss: 0.2577 - accuracy: 0.9050 - val_loss: 0.4243 - val_accuracy: 0.8301\n",
      "Epoch 8/20\n",
      "33/33 - 57s - loss: 0.3051 - accuracy: 0.8871 - val_loss: 0.4545 - val_accuracy: 0.8533\n",
      "9/9 [==============================] - 2s 190ms/step - loss: 0.3467 - accuracy: 0.8610\n",
      "INFO:tensorflow:Assets written to: saved_models/Model_Male/Run-9/assets\n",
      "--- Starting trial: run-10\n",
      "{'filter_size_1': 5, 'filters_number': 96, 'filter_size_2': 5, 'dense_size': 256}\n",
      "Epoch 1/20\n",
      "33/33 - 97s - loss: 1.9332 - accuracy: 0.4583 - val_loss: 0.7055 - val_accuracy: 0.7336\n",
      "Epoch 2/20\n",
      "33/33 - 92s - loss: 0.6913 - accuracy: 0.7501 - val_loss: 0.4794 - val_accuracy: 0.8301\n",
      "Epoch 3/20\n",
      "33/33 - 94s - loss: 0.5482 - accuracy: 0.7988 - val_loss: 0.4672 - val_accuracy: 0.8340\n",
      "Epoch 4/20\n",
      "33/33 - 95s - loss: 0.4659 - accuracy: 0.8244 - val_loss: 0.5426 - val_accuracy: 0.8031\n",
      "Epoch 5/20\n",
      "33/33 - 92s - loss: 0.4042 - accuracy: 0.8490 - val_loss: 0.3631 - val_accuracy: 0.8764\n",
      "Epoch 6/20\n",
      "33/33 - 91s - loss: 0.3664 - accuracy: 0.8688 - val_loss: 0.4152 - val_accuracy: 0.8494\n",
      "Epoch 7/20\n",
      "33/33 - 94s - loss: 0.3353 - accuracy: 0.8683 - val_loss: 0.3359 - val_accuracy: 0.8726\n",
      "Epoch 8/20\n",
      "33/33 - 117s - loss: 0.2849 - accuracy: 0.8924 - val_loss: 0.4097 - val_accuracy: 0.8494\n",
      "Epoch 9/20\n",
      "33/33 - 92s - loss: 0.2743 - accuracy: 0.9035 - val_loss: 0.3274 - val_accuracy: 0.8726\n",
      "Epoch 10/20\n",
      "33/33 - 153s - loss: 0.2204 - accuracy: 0.9156 - val_loss: 0.3433 - val_accuracy: 0.8764\n",
      "Epoch 11/20\n",
      "33/33 - 94s - loss: 0.1906 - accuracy: 0.9286 - val_loss: 0.3294 - val_accuracy: 0.8919\n",
      "9/9 [==============================] - 3s 334ms/step - loss: 0.3274 - accuracy: 0.8726\n",
      "INFO:tensorflow:Assets written to: saved_models/Model_Male/Run-10/assets\n",
      "--- Starting trial: run-11\n",
      "{'filter_size_1': 5, 'filters_number': 128, 'filter_size_2': 3, 'dense_size': 256}\n",
      "Epoch 1/20\n",
      "33/33 - 83s - loss: 1.6446 - accuracy: 0.5109 - val_loss: 0.8639 - val_accuracy: 0.6757\n",
      "Epoch 2/20\n",
      "33/33 - 94s - loss: 0.6814 - accuracy: 0.7482 - val_loss: 0.5126 - val_accuracy: 0.8224\n",
      "Epoch 3/20\n",
      "33/33 - 94s - loss: 0.5381 - accuracy: 0.8032 - val_loss: 0.4866 - val_accuracy: 0.8340\n",
      "Epoch 4/20\n",
      "33/33 - 81s - loss: 0.4344 - accuracy: 0.8389 - val_loss: 0.6482 - val_accuracy: 0.7413\n",
      "Epoch 5/20\n",
      "33/33 - 93s - loss: 0.4349 - accuracy: 0.8480 - val_loss: 0.3868 - val_accuracy: 0.8494\n",
      "Epoch 6/20\n",
      "33/33 - 89s - loss: 0.3635 - accuracy: 0.8693 - val_loss: 0.4391 - val_accuracy: 0.8456\n",
      "Epoch 7/20\n",
      "33/33 - 101s - loss: 0.3247 - accuracy: 0.8818 - val_loss: 0.3588 - val_accuracy: 0.8880\n",
      "Epoch 8/20\n",
      "33/33 - 86s - loss: 0.2746 - accuracy: 0.9035 - val_loss: 0.3650 - val_accuracy: 0.8842\n",
      "Epoch 9/20\n",
      "33/33 - 93s - loss: 0.2556 - accuracy: 0.9050 - val_loss: 0.3626 - val_accuracy: 0.8803\n",
      "9/9 [==============================] - 7s 716ms/step - loss: 0.3588 - accuracy: 0.8880\n",
      "INFO:tensorflow:Assets written to: saved_models/Model_Male/Run-11/assets\n",
      "--- Starting trial: run-12\n",
      "{'filter_size_1': 5, 'filters_number': 128, 'filter_size_2': 5, 'dense_size': 256}\n",
      "Epoch 1/20\n",
      "33/33 - 195s - loss: 2.0518 - accuracy: 0.5041 - val_loss: 0.9952 - val_accuracy: 0.6988\n",
      "Epoch 2/20\n",
      "33/33 - 168s - loss: 0.7572 - accuracy: 0.7246 - val_loss: 0.5211 - val_accuracy: 0.8069\n",
      "Epoch 3/20\n",
      "33/33 - 152s - loss: 0.5789 - accuracy: 0.7926 - val_loss: 0.5461 - val_accuracy: 0.8108\n",
      "Epoch 4/20\n",
      "33/33 - 148s - loss: 0.5395 - accuracy: 0.8041 - val_loss: 0.5005 - val_accuracy: 0.8378\n",
      "Epoch 5/20\n",
      "33/33 - 146s - loss: 0.4429 - accuracy: 0.8427 - val_loss: 0.3971 - val_accuracy: 0.8417\n",
      "Epoch 6/20\n",
      "33/33 - 146s - loss: 0.4264 - accuracy: 0.8394 - val_loss: 0.4864 - val_accuracy: 0.8340\n",
      "Epoch 7/20\n",
      "33/33 - 144s - loss: 0.3462 - accuracy: 0.8780 - val_loss: 0.3700 - val_accuracy: 0.8649\n",
      "Epoch 8/20\n",
      "33/33 - 147s - loss: 0.2910 - accuracy: 0.8973 - val_loss: 0.4102 - val_accuracy: 0.8610\n",
      "Epoch 9/20\n",
      "33/33 - 143s - loss: 0.2562 - accuracy: 0.9040 - val_loss: 0.4343 - val_accuracy: 0.8687\n",
      "9/9 [==============================] - 6s 614ms/step - loss: 0.3700 - accuracy: 0.8649\n",
      "INFO:tensorflow:Assets written to: saved_models/Model_Male/Run-12/assets\n",
      "--- Starting trial: run-13\n",
      "{'filter_size_1': 7, 'filters_number': 64, 'filter_size_2': 3, 'dense_size': 256}\n",
      "Epoch 1/20\n",
      "33/33 - 42s - loss: 1.7800 - accuracy: 0.4443 - val_loss: 0.7108 - val_accuracy: 0.7761\n",
      "Epoch 2/20\n",
      "33/33 - 41s - loss: 0.6898 - accuracy: 0.7549 - val_loss: 0.5086 - val_accuracy: 0.8224\n",
      "Epoch 3/20\n",
      "33/33 - 42s - loss: 0.5034 - accuracy: 0.8099 - val_loss: 0.4416 - val_accuracy: 0.8263\n",
      "Epoch 4/20\n",
      "33/33 - 40s - loss: 0.4427 - accuracy: 0.8341 - val_loss: 0.4145 - val_accuracy: 0.8610\n",
      "Epoch 5/20\n",
      "33/33 - 43s - loss: 0.4163 - accuracy: 0.8543 - val_loss: 0.3872 - val_accuracy: 0.8571\n",
      "Epoch 6/20\n",
      "33/33 - 43s - loss: 0.3805 - accuracy: 0.8553 - val_loss: 0.4225 - val_accuracy: 0.8456\n",
      "Epoch 7/20\n",
      "33/33 - 44s - loss: 0.3306 - accuracy: 0.8823 - val_loss: 0.3572 - val_accuracy: 0.8842\n",
      "Epoch 8/20\n",
      "33/33 - 41s - loss: 0.3012 - accuracy: 0.8862 - val_loss: 0.3440 - val_accuracy: 0.8726\n",
      "Epoch 9/20\n",
      "33/33 - 44s - loss: 0.2906 - accuracy: 0.8900 - val_loss: 0.3410 - val_accuracy: 0.8726\n",
      "Epoch 10/20\n",
      "33/33 - 41s - loss: 0.2517 - accuracy: 0.9083 - val_loss: 0.3815 - val_accuracy: 0.8571\n",
      "Epoch 11/20\n",
      "33/33 - 49s - loss: 0.2445 - accuracy: 0.9074 - val_loss: 0.3223 - val_accuracy: 0.8919\n",
      "Epoch 12/20\n",
      "33/33 - 39s - loss: 0.2035 - accuracy: 0.9257 - val_loss: 0.3853 - val_accuracy: 0.8919\n",
      "Epoch 13/20\n",
      "33/33 - 38s - loss: 0.2191 - accuracy: 0.9204 - val_loss: 0.3522 - val_accuracy: 0.8842\n",
      "9/9 [==============================] - 1s 132ms/step - loss: 0.3223 - accuracy: 0.8919\n",
      "INFO:tensorflow:Assets written to: saved_models/Model_Male/Run-13/assets\n",
      "--- Starting trial: run-14\n",
      "{'filter_size_1': 7, 'filters_number': 64, 'filter_size_2': 5, 'dense_size': 256}\n",
      "Epoch 1/20\n",
      "33/33 - 58s - loss: 1.5917 - accuracy: 0.4337 - val_loss: 0.7527 - val_accuracy: 0.7606\n",
      "Epoch 2/20\n",
      "33/33 - 56s - loss: 0.7086 - accuracy: 0.7438 - val_loss: 0.6984 - val_accuracy: 0.7645\n",
      "Epoch 3/20\n",
      "33/33 - 66s - loss: 0.6051 - accuracy: 0.7824 - val_loss: 0.4636 - val_accuracy: 0.8263\n",
      "Epoch 4/20\n",
      "33/33 - 59s - loss: 0.4894 - accuracy: 0.8210 - val_loss: 0.4435 - val_accuracy: 0.8263\n",
      "Epoch 5/20\n",
      "33/33 - 57s - loss: 0.4129 - accuracy: 0.8538 - val_loss: 0.4708 - val_accuracy: 0.8301\n",
      "Epoch 6/20\n",
      "33/33 - 58s - loss: 0.4336 - accuracy: 0.8432 - val_loss: 0.4198 - val_accuracy: 0.8301\n",
      "Epoch 7/20\n",
      "33/33 - 72s - loss: 0.3868 - accuracy: 0.8562 - val_loss: 0.4313 - val_accuracy: 0.8494\n",
      "Epoch 8/20\n",
      "33/33 - 70s - loss: 0.3596 - accuracy: 0.8789 - val_loss: 0.3692 - val_accuracy: 0.8494\n",
      "Epoch 9/20\n",
      "33/33 - 68s - loss: 0.3206 - accuracy: 0.8813 - val_loss: 0.4904 - val_accuracy: 0.7954\n",
      "Epoch 10/20\n",
      "33/33 - 66s - loss: 0.3384 - accuracy: 0.8823 - val_loss: 0.3765 - val_accuracy: 0.8378\n",
      "9/9 [==============================] - 2s 187ms/step - loss: 0.3692 - accuracy: 0.8494\n",
      "INFO:tensorflow:Assets written to: saved_models/Model_Male/Run-14/assets\n",
      "--- Starting trial: run-15\n",
      "{'filter_size_1': 7, 'filters_number': 96, 'filter_size_2': 3, 'dense_size': 256}\n",
      "Epoch 1/20\n",
      "33/33 - 64s - loss: 1.5169 - accuracy: 0.5470 - val_loss: 0.5581 - val_accuracy: 0.8069\n",
      "Epoch 2/20\n",
      "33/33 - 68s - loss: 0.6148 - accuracy: 0.7685 - val_loss: 0.4844 - val_accuracy: 0.8185\n",
      "Epoch 3/20\n",
      "33/33 - 67s - loss: 0.5151 - accuracy: 0.8162 - val_loss: 0.4484 - val_accuracy: 0.8301\n",
      "Epoch 4/20\n",
      "33/33 - 67s - loss: 0.4329 - accuracy: 0.8432 - val_loss: 0.4409 - val_accuracy: 0.8263\n",
      "Epoch 5/20\n",
      "33/33 - 70s - loss: 0.4060 - accuracy: 0.8534 - val_loss: 0.3777 - val_accuracy: 0.8533\n",
      "Epoch 6/20\n",
      "33/33 - 69s - loss: 0.3934 - accuracy: 0.8524 - val_loss: 0.3970 - val_accuracy: 0.8610\n",
      "Epoch 7/20\n",
      "33/33 - 70s - loss: 0.3310 - accuracy: 0.8833 - val_loss: 0.3616 - val_accuracy: 0.8649\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/20\n",
      "33/33 - 70s - loss: 0.2904 - accuracy: 0.8919 - val_loss: 0.3817 - val_accuracy: 0.8764\n",
      "Epoch 9/20\n",
      "33/33 - 73s - loss: 0.2994 - accuracy: 0.8876 - val_loss: 0.3536 - val_accuracy: 0.8610\n",
      "Epoch 10/20\n",
      "33/33 - 75s - loss: 0.2333 - accuracy: 0.9161 - val_loss: 0.3390 - val_accuracy: 0.8687\n",
      "Epoch 11/20\n",
      "33/33 - 70s - loss: 0.2129 - accuracy: 0.9194 - val_loss: 0.4782 - val_accuracy: 0.8649\n",
      "Epoch 12/20\n",
      "33/33 - 74s - loss: 0.2593 - accuracy: 0.9006 - val_loss: 0.4682 - val_accuracy: 0.8764\n",
      "9/9 [==============================] - 3s 289ms/step - loss: 0.3390 - accuracy: 0.8687\n",
      "INFO:tensorflow:Assets written to: saved_models/Model_Male/Run-15/assets\n",
      "--- Starting trial: run-16\n",
      "{'filter_size_1': 7, 'filters_number': 96, 'filter_size_2': 5, 'dense_size': 256}\n",
      "Epoch 1/20\n",
      "33/33 - 120s - loss: 1.5821 - accuracy: 0.5287 - val_loss: 0.6638 - val_accuracy: 0.7490\n",
      "Epoch 2/20\n",
      "33/33 - 118s - loss: 0.6289 - accuracy: 0.7670 - val_loss: 0.4983 - val_accuracy: 0.8301\n",
      "Epoch 3/20\n",
      "33/33 - 119s - loss: 0.5284 - accuracy: 0.8037 - val_loss: 0.4960 - val_accuracy: 0.8263\n",
      "Epoch 4/20\n",
      "33/33 - 2382s - loss: 0.4954 - accuracy: 0.8138 - val_loss: 0.4697 - val_accuracy: 0.8456\n",
      "Epoch 5/20\n",
      "33/33 - 2057s - loss: 0.4575 - accuracy: 0.8336 - val_loss: 0.4555 - val_accuracy: 0.8340\n",
      "Epoch 6/20\n",
      "33/33 - 102s - loss: 0.3928 - accuracy: 0.8534 - val_loss: 0.3846 - val_accuracy: 0.8726\n",
      "Epoch 7/20\n",
      "33/33 - 112s - loss: 0.3174 - accuracy: 0.8857 - val_loss: 0.3983 - val_accuracy: 0.8533\n",
      "Epoch 8/20\n",
      "33/33 - 117s - loss: 0.3052 - accuracy: 0.8837 - val_loss: 0.4115 - val_accuracy: 0.8649\n",
      "9/9 [==============================] - 5s 484ms/step - loss: 0.3846 - accuracy: 0.8726\n",
      "INFO:tensorflow:Assets written to: saved_models/Model_Male/Run-16/assets\n",
      "--- Starting trial: run-17\n",
      "{'filter_size_1': 7, 'filters_number': 128, 'filter_size_2': 3, 'dense_size': 256}\n",
      "Epoch 1/20\n",
      "33/33 - 108s - loss: 1.3615 - accuracy: 0.5027 - val_loss: 0.6604 - val_accuracy: 0.7799\n",
      "Epoch 2/20\n",
      "33/33 - 107s - loss: 0.6145 - accuracy: 0.7704 - val_loss: 0.4652 - val_accuracy: 0.8301\n",
      "Epoch 3/20\n",
      "33/33 - 109s - loss: 0.4978 - accuracy: 0.8177 - val_loss: 0.4177 - val_accuracy: 0.8533\n",
      "Epoch 4/20\n",
      "33/33 - 109s - loss: 0.4431 - accuracy: 0.8278 - val_loss: 0.3949 - val_accuracy: 0.8571\n",
      "Epoch 5/20\n",
      "33/33 - 115s - loss: 0.3797 - accuracy: 0.8553 - val_loss: 0.3572 - val_accuracy: 0.8610\n",
      "Epoch 6/20\n",
      "33/33 - 113s - loss: 0.3211 - accuracy: 0.8808 - val_loss: 0.3602 - val_accuracy: 0.8649\n",
      "Epoch 7/20\n",
      "33/33 - 114s - loss: 0.3132 - accuracy: 0.8823 - val_loss: 0.3959 - val_accuracy: 0.8494\n",
      "9/9 [==============================] - 5s 542ms/step - loss: 0.3572 - accuracy: 0.8610\n",
      "INFO:tensorflow:Assets written to: saved_models/Model_Male/Run-17/assets\n",
      "--- Starting trial: run-18\n",
      "{'filter_size_1': 7, 'filters_number': 128, 'filter_size_2': 5, 'dense_size': 256}\n",
      "Epoch 1/20\n",
      "33/33 - 3112s - loss: 1.5449 - accuracy: 0.5084 - val_loss: 0.7224 - val_accuracy: 0.7529\n",
      "Epoch 2/20\n",
      "33/33 - 164s - loss: 0.6365 - accuracy: 0.7607 - val_loss: 0.5093 - val_accuracy: 0.7992\n",
      "Epoch 3/20\n",
      "33/33 - 187s - loss: 0.5359 - accuracy: 0.8066 - val_loss: 0.4623 - val_accuracy: 0.8533\n",
      "Epoch 4/20\n",
      "33/33 - 188s - loss: 0.4721 - accuracy: 0.8254 - val_loss: 0.4218 - val_accuracy: 0.8340\n",
      "Epoch 5/20\n",
      "33/33 - 192s - loss: 0.4007 - accuracy: 0.8519 - val_loss: 0.3971 - val_accuracy: 0.8533\n",
      "Epoch 6/20\n",
      "33/33 - 197s - loss: 0.3654 - accuracy: 0.8717 - val_loss: 0.4370 - val_accuracy: 0.8263\n",
      "Epoch 7/20\n",
      "33/33 - 197s - loss: 0.3233 - accuracy: 0.8808 - val_loss: 0.4164 - val_accuracy: 0.8263\n",
      "9/9 [==============================] - 8s 829ms/step - loss: 0.3971 - accuracy: 0.8533\n",
      "INFO:tensorflow:Assets written to: saved_models/Model_Male/Run-18/assets\n"
     ]
    }
   ],
   "source": [
    "session_num = 1\n",
    "\n",
    "for filter_size_1 in HP_FILTER_SIZE_1.domain.values:\n",
    "    for filter_num in HP_FILTER_NUM.domain.values:\n",
    "        for filter_size_2 in HP_FILTER_SIZE_2.domain.values:\n",
    "            for dense_size in HP_DENSE_SIZE.domain.values:\n",
    "            \n",
    "                hparams = {\n",
    "                    HP_FILTER_SIZE_1: filter_size_1,\n",
    "                    HP_FILTER_NUM: filter_num,\n",
    "                    HP_FILTER_SIZE_2: filter_size_2,\n",
    "                    HP_DENSE_SIZE: dense_size\n",
    "                }\n",
    "\n",
    "                run_name = \"run-%d\" % session_num\n",
    "                print('--- Starting trial: %s' % run_name)\n",
    "                print({h.name: hparams[h] for h in hparams})\n",
    "                run('Logs/Model_Male/hparam_tuning/' + run_name, hparams, session_num)\n",
    "\n",
    "                session_num += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading a model to evaluate on the test set\n",
    "model = tf.keras.models.load_model(r\"saved_models/Model_Male/Run-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 1s 128ms/step - loss: 0.3995 - accuracy: 0.8687\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(images_test,labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.3995. Test accuracy: 86.87%\n"
     ]
    }
   ],
   "source": [
    "# Printing the test results\n",
    "print('Test loss: {0:.4f}. Test accuracy: {1:.2f}%'.format(test_loss, test_accuracy*100.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir \"Logs/Model_Male/hparam_tuning\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir \"Logs/Model_Male/fit\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
