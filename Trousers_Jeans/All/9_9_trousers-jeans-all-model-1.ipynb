{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import itertools\n",
    "\n",
    "import numpy as np\n",
    "import sklearn.metrics\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorboard.plugins.hparams import api as hp\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the datasets\n",
    "data_train = np.load(r\"Dataset/Trousers & Jeans - All - Train.npz\")\n",
    "data_val = np.load(r\"Dataset/Trousers & Jeans - All - Validation.npz\")\n",
    "data_test = np.load(r\"Dataset/Trousers & Jeans - All - Test.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting the arrays from the imported data\n",
    "images_train = data_train['images']\n",
    "labels_train = data_train['labels']\n",
    "\n",
    "images_val = data_val['images']\n",
    "labels_val = data_val['labels']\n",
    "\n",
    "images_test = data_test['images']\n",
    "labels_test = data_test['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling the pixel values of all images \n",
    "images_train = images_train/255.0\n",
    "images_val = images_val/255.0\n",
    "images_test = images_test/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the hyperparameters we would tune, and their values to be tested\n",
    "HP_FILTER_SIZE = hp.HParam('filter_size', hp.Discrete([3,5,7]))\n",
    "HP_FILTER_NUM = hp.HParam('filters_number', hp.Discrete([32,64,96,128]))\n",
    "\n",
    "METRIC_ACCURACY = 'accuracy'\n",
    "\n",
    "# Logging setup info\n",
    "with tf.summary.create_file_writer(r'Logs/Model 1/hparam_tuning/').as_default():\n",
    "    hp.hparams_config(\n",
    "        hparams=[HP_FILTER_SIZE, HP_FILTER_NUM],\n",
    "        metrics=[hp.Metric(METRIC_ACCURACY, display_name='Accuracy')],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 20\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrapping our model and training in a function\n",
    "def train_test_model(hparams, session_num):\n",
    "    \n",
    "    # Outlining the model/architecture of our CNN\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Conv2D(hparams[HP_FILTER_NUM], hparams[HP_FILTER_SIZE], activation='relu', input_shape=(120,90,3)),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(4)\n",
    "    ])\n",
    "    \n",
    "    # Defining the loss function\n",
    "    loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "    # Compiling the model\n",
    "    model.compile(optimizer='adam', loss=loss_fn, metrics=['accuracy'])\n",
    "\n",
    "    # Defining the logging directory\n",
    "    log_dir = \"Logs/Model 1/fit/\" + \"run-{}\".format(session_num)\n",
    "    \n",
    "    def plot_confusion_matrix(cm, class_names):\n",
    "        \"\"\"\n",
    "        Returns a matplotlib figure containing the plotted confusion matrix.\n",
    "\n",
    "        Args:\n",
    "          cm (array, shape = [n, n]): a confusion matrix of integer classes\n",
    "          class_names (array, shape = [n]): String names of the integer classes\n",
    "        \"\"\"\n",
    "        figure = plt.figure(figsize=(12, 12))\n",
    "        plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "        plt.title(\"Confusion matrix\")\n",
    "        plt.colorbar()\n",
    "        tick_marks = np.arange(len(class_names))\n",
    "        plt.xticks(tick_marks, class_names, rotation=45)\n",
    "        plt.yticks(tick_marks, class_names)\n",
    "\n",
    "        # Normalize the confusion matrix.\n",
    "        cm = np.around(cm.astype('float') / cm.sum(axis=1)[:, np.newaxis], decimals=2)\n",
    "\n",
    "        # Use white text if squares are dark; otherwise black.\n",
    "        threshold = cm.max() / 2.\n",
    "        for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "            color = \"white\" if cm[i, j] > threshold else \"black\"\n",
    "            plt.text(j, i, cm[i, j], horizontalalignment=\"center\", color=color)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.ylabel('True label')\n",
    "        plt.xlabel('Predicted label')\n",
    "        return figure\n",
    "    \n",
    "     \n",
    "    \n",
    "    \n",
    "    def plot_to_image(figure):\n",
    "        \"\"\"Converts the matplotlib plot specified by 'figure' to a PNG image and\n",
    "        returns it. The supplied figure is closed and inaccessible after this call.\"\"\"\n",
    "        # Save the plot to a PNG in memory.\n",
    "        buf = io.BytesIO()\n",
    "        plt.savefig(buf, format='png')\n",
    "        # Closing the figure prevents it from being displayed directly inside\n",
    "        # the notebook.\n",
    "        plt.close(figure)\n",
    "        buf.seek(0)\n",
    "        # Convert PNG buffer to TF image\n",
    "        image = tf.image.decode_png(buf.getvalue(), channels=4)\n",
    "        # Add the batch dimension\n",
    "        image = tf.expand_dims(image, 0)\n",
    "        return image\n",
    "    \n",
    "    \n",
    "    # Defining a file writer for Confusion Matrix logging purposes\n",
    "    file_writer_cm = tf.summary.create_file_writer(log_dir + '/cm') \n",
    "    \n",
    "    \n",
    "    def log_confusion_matrix(epoch, logs):\n",
    "        # Use the model to predict the values from the validation dataset.\n",
    "        test_pred_raw = model.predict(images_val)\n",
    "        test_pred = np.argmax(test_pred_raw, axis=1)\n",
    "\n",
    "        # Calculate the confusion matrix.\n",
    "        cm = sklearn.metrics.confusion_matrix(labels_val, test_pred)\n",
    "        # Log the confusion matrix as an image summary.\n",
    "        figure = plot_confusion_matrix(cm, class_names=['Trousers Male', 'Jeans Male', 'Trousers Female', \"Jeans Female\"])\n",
    "        cm_image = plot_to_image(figure)\n",
    "\n",
    "        # Log the confusion matrix as an image summary.\n",
    "        with file_writer_cm.as_default():\n",
    "            tf.summary.image(\"Confusion Matrix\", cm_image, step=epoch)\n",
    "    \n",
    "    \n",
    "    # Define the Tensorboard and Confusion Matrix callbacks.\n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1, profile_batch=0)\n",
    "    cm_callback = tf.keras.callbacks.LambdaCallback(on_epoch_end=log_confusion_matrix)\n",
    "\n",
    "    \n",
    "    # Defining early stopping to prevent overfitting\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "        monitor = 'val_loss',\n",
    "        mode = 'auto',\n",
    "        min_delta = 0,\n",
    "        patience = 2,\n",
    "        verbose = 0, \n",
    "        restore_best_weights = True\n",
    "    )\n",
    "    \n",
    "    # Training the model\n",
    "    model.fit(\n",
    "        images_train,\n",
    "        labels_train,\n",
    "        epochs = EPOCHS,\n",
    "        batch_size = BATCH_SIZE,\n",
    "        callbacks = [tensorboard_callback, cm_callback, early_stopping],\n",
    "        validation_data = (images_val,labels_val),\n",
    "        verbose = 2\n",
    "    )\n",
    "    \n",
    "    # Evaluating the model's performance on the validation set\n",
    "    _, accuracy = model.evaluate(images_val,labels_val)\n",
    "    \n",
    "    # Saving the current model for future reference\n",
    "    model.save(r\"saved_models/Model 1/Run-{}\".format(session_num))\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a function to log the resuls\n",
    "def run(log_dir, hparams, session_num):\n",
    "    \n",
    "    with tf.summary.create_file_writer(log_dir).as_default():\n",
    "        hp.hparams(hparams)  # record the values used in this trial\n",
    "        accuracy = train_test_model(hparams, session_num)\n",
    "        tf.summary.scalar(METRIC_ACCURACY, accuracy, step=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting trial: run-1\n",
      "{'filter_size': 3, 'filters_number': 32}\n",
      "Epoch 1/20\n",
      "63/63 - 18s - loss: 6.4006 - accuracy: 0.4291 - val_loss: 1.0554 - val_accuracy: 0.5720\n",
      "Epoch 2/20\n",
      "63/63 - 15s - loss: 0.8807 - accuracy: 0.6451 - val_loss: 0.9674 - val_accuracy: 0.6060\n",
      "Epoch 3/20\n",
      "63/63 - 13s - loss: 0.7163 - accuracy: 0.7203 - val_loss: 0.8793 - val_accuracy: 0.6360\n",
      "Epoch 4/20\n",
      "63/63 - 14s - loss: 0.6380 - accuracy: 0.7545 - val_loss: 0.8512 - val_accuracy: 0.6600\n",
      "Epoch 5/20\n",
      "63/63 - 16s - loss: 0.5794 - accuracy: 0.7737 - val_loss: 0.8095 - val_accuracy: 0.6740\n",
      "Epoch 6/20\n",
      "63/63 - 17s - loss: 0.5282 - accuracy: 0.8002 - val_loss: 0.8241 - val_accuracy: 0.6940\n",
      "Epoch 7/20\n",
      "63/63 - 15s - loss: 0.4700 - accuracy: 0.8284 - val_loss: 0.8158 - val_accuracy: 0.6720\n",
      "16/16 [==============================] - 1s 47ms/step - loss: 0.8095 - accuracy: 0.6740\n",
      "INFO:tensorflow:Assets written to: saved_models/Model 1/Run-1/assets\n",
      "--- Starting trial: run-2\n",
      "{'filter_size': 3, 'filters_number': 64}\n",
      "Epoch 1/20\n",
      "63/63 - 51s - loss: 6.1082 - accuracy: 0.4553 - val_loss: 1.0974 - val_accuracy: 0.5900\n",
      "Epoch 2/20\n",
      "63/63 - 36s - loss: 0.8484 - accuracy: 0.6736 - val_loss: 0.9873 - val_accuracy: 0.6100\n",
      "Epoch 3/20\n",
      "63/63 - 38s - loss: 0.7099 - accuracy: 0.7188 - val_loss: 0.8766 - val_accuracy: 0.6780\n",
      "Epoch 4/20\n",
      "63/63 - 28s - loss: 0.6104 - accuracy: 0.7640 - val_loss: 0.8550 - val_accuracy: 0.6800\n",
      "Epoch 5/20\n",
      "63/63 - 32s - loss: 0.5438 - accuracy: 0.8007 - val_loss: 0.9029 - val_accuracy: 0.6540\n",
      "Epoch 6/20\n",
      "63/63 - 27s - loss: 0.4877 - accuracy: 0.8207 - val_loss: 0.8600 - val_accuracy: 0.6980\n",
      "16/16 [==============================] - 1s 46ms/step - loss: 0.8550 - accuracy: 0.6800\n",
      "INFO:tensorflow:Assets written to: saved_models/Model 1/Run-2/assets\n",
      "--- Starting trial: run-3\n",
      "{'filter_size': 3, 'filters_number': 96}\n",
      "Epoch 1/20\n",
      "63/63 - 44s - loss: 5.9666 - accuracy: 0.4650 - val_loss: 1.0337 - val_accuracy: 0.6160\n",
      "Epoch 2/20\n",
      "63/63 - 42s - loss: 0.8715 - accuracy: 0.6556 - val_loss: 0.9282 - val_accuracy: 0.6160\n",
      "Epoch 3/20\n",
      "63/63 - 39s - loss: 0.7363 - accuracy: 0.7205 - val_loss: 0.8785 - val_accuracy: 0.6660\n",
      "Epoch 4/20\n",
      "63/63 - 39s - loss: 0.6541 - accuracy: 0.7547 - val_loss: 0.8725 - val_accuracy: 0.6680\n",
      "Epoch 5/20\n",
      "63/63 - 43s - loss: 0.5569 - accuracy: 0.7970 - val_loss: 0.8519 - val_accuracy: 0.6840\n",
      "Epoch 6/20\n",
      "63/63 - 49s - loss: 0.5183 - accuracy: 0.8002 - val_loss: 0.8445 - val_accuracy: 0.7100\n",
      "Epoch 7/20\n",
      "63/63 - 38s - loss: 0.4860 - accuracy: 0.8187 - val_loss: 0.9339 - val_accuracy: 0.6600\n",
      "Epoch 8/20\n",
      "63/63 - 39s - loss: 0.4094 - accuracy: 0.8606 - val_loss: 0.9331 - val_accuracy: 0.6640\n",
      "16/16 [==============================] - 1s 63ms/step - loss: 0.8445 - accuracy: 0.7100\n",
      "INFO:tensorflow:Assets written to: saved_models/Model 1/Run-3/assets\n",
      "--- Starting trial: run-4\n",
      "{'filter_size': 3, 'filters_number': 128}\n",
      "Epoch 1/20\n",
      "63/63 - 52s - loss: 10.2283 - accuracy: 0.4498 - val_loss: 1.0236 - val_accuracy: 0.6060\n",
      "Epoch 2/20\n",
      "63/63 - 52s - loss: 0.8415 - accuracy: 0.6598 - val_loss: 0.9487 - val_accuracy: 0.6240\n",
      "Epoch 3/20\n",
      "63/63 - 54s - loss: 0.7634 - accuracy: 0.6961 - val_loss: 0.9161 - val_accuracy: 0.6540\n",
      "Epoch 4/20\n",
      "63/63 - 51s - loss: 0.6352 - accuracy: 0.7495 - val_loss: 0.9021 - val_accuracy: 0.6560\n",
      "Epoch 5/20\n",
      "63/63 - 51s - loss: 0.5669 - accuracy: 0.7825 - val_loss: 0.8539 - val_accuracy: 0.6740\n",
      "Epoch 6/20\n",
      "63/63 - 47s - loss: 0.5079 - accuracy: 0.8057 - val_loss: 0.8726 - val_accuracy: 0.6780\n",
      "Epoch 7/20\n",
      "63/63 - 50s - loss: 0.4419 - accuracy: 0.8357 - val_loss: 0.9047 - val_accuracy: 0.7000\n",
      "16/16 [==============================] - 2s 128ms/step - loss: 0.8539 - accuracy: 0.6740\n",
      "INFO:tensorflow:Assets written to: saved_models/Model 1/Run-4/assets\n",
      "--- Starting trial: run-5\n",
      "{'filter_size': 5, 'filters_number': 32}\n",
      "Epoch 1/20\n",
      "63/63 - 22s - loss: 2.8122 - accuracy: 0.4486 - val_loss: 1.0859 - val_accuracy: 0.5780\n",
      "Epoch 2/20\n",
      "63/63 - 21s - loss: 0.9129 - accuracy: 0.6466 - val_loss: 0.9239 - val_accuracy: 0.6520\n",
      "Epoch 3/20\n",
      "63/63 - 21s - loss: 0.8120 - accuracy: 0.6893 - val_loss: 0.9487 - val_accuracy: 0.6380\n",
      "Epoch 4/20\n",
      "63/63 - 20s - loss: 0.7012 - accuracy: 0.7315 - val_loss: 0.9214 - val_accuracy: 0.6200\n",
      "Epoch 5/20\n",
      "63/63 - 21s - loss: 0.6855 - accuracy: 0.7378 - val_loss: 0.8774 - val_accuracy: 0.6760\n",
      "Epoch 6/20\n",
      "63/63 - 22s - loss: 0.6819 - accuracy: 0.7605 - val_loss: 0.9217 - val_accuracy: 0.6260\n",
      "Epoch 7/20\n",
      "63/63 - 20s - loss: 0.5928 - accuracy: 0.7750 - val_loss: 0.8688 - val_accuracy: 0.6700\n",
      "Epoch 8/20\n",
      "63/63 - 19s - loss: 0.5276 - accuracy: 0.8142 - val_loss: 0.8339 - val_accuracy: 0.6800\n",
      "Epoch 9/20\n",
      "63/63 - 20s - loss: 0.6228 - accuracy: 0.7772 - val_loss: 0.9304 - val_accuracy: 0.6580\n",
      "Epoch 10/20\n",
      "63/63 - 21s - loss: 0.5302 - accuracy: 0.7980 - val_loss: 0.8575 - val_accuracy: 0.6620\n",
      "16/16 [==============================] - 1s 46ms/step - loss: 0.8339 - accuracy: 0.6800\n",
      "INFO:tensorflow:Assets written to: saved_models/Model 1/Run-5/assets\n",
      "--- Starting trial: run-6\n",
      "{'filter_size': 5, 'filters_number': 64}\n",
      "Epoch 1/20\n",
      "63/63 - 40s - loss: 4.2336 - accuracy: 0.4863 - val_loss: 1.0284 - val_accuracy: 0.6120\n",
      "Epoch 2/20\n",
      "63/63 - 40s - loss: 0.8879 - accuracy: 0.6436 - val_loss: 0.9268 - val_accuracy: 0.6320\n",
      "Epoch 3/20\n",
      "63/63 - 41s - loss: 0.7723 - accuracy: 0.6971 - val_loss: 0.8728 - val_accuracy: 0.6620\n",
      "Epoch 4/20\n",
      "63/63 - 34s - loss: 0.7732 - accuracy: 0.7043 - val_loss: 0.9054 - val_accuracy: 0.6260\n",
      "Epoch 5/20\n",
      "63/63 - 46s - loss: 0.6550 - accuracy: 0.7420 - val_loss: 0.8894 - val_accuracy: 0.6400\n",
      "16/16 [==============================] - 2s 104ms/step - loss: 0.8728 - accuracy: 0.6620\n",
      "INFO:tensorflow:Assets written to: saved_models/Model 1/Run-6/assets\n",
      "--- Starting trial: run-7\n",
      "{'filter_size': 5, 'filters_number': 96}\n",
      "Epoch 1/20\n",
      "63/63 - 57s - loss: 3.8165 - accuracy: 0.4843 - val_loss: 0.9783 - val_accuracy: 0.6320\n",
      "Epoch 2/20\n",
      "63/63 - 51s - loss: 0.9140 - accuracy: 0.6401 - val_loss: 0.9447 - val_accuracy: 0.5920\n",
      "Epoch 3/20\n",
      "63/63 - 51s - loss: 0.8359 - accuracy: 0.6716 - val_loss: 1.3186 - val_accuracy: 0.5000\n",
      "Epoch 4/20\n",
      "63/63 - 53s - loss: 0.7508 - accuracy: 0.7003 - val_loss: 0.8387 - val_accuracy: 0.6640\n",
      "Epoch 5/20\n",
      "63/63 - 51s - loss: 0.6964 - accuracy: 0.7218 - val_loss: 0.8655 - val_accuracy: 0.6560\n",
      "Epoch 6/20\n",
      "63/63 - 50s - loss: 0.8562 - accuracy: 0.6898 - val_loss: 0.9530 - val_accuracy: 0.6720\n",
      "16/16 [==============================] - 1s 90ms/step - loss: 0.8387 - accuracy: 0.6640\n",
      "INFO:tensorflow:Assets written to: saved_models/Model 1/Run-7/assets\n",
      "--- Starting trial: run-8\n",
      "{'filter_size': 5, 'filters_number': 128}\n",
      "Epoch 1/20\n",
      "63/63 - 65s - loss: 3.5547 - accuracy: 0.4578 - val_loss: 1.1074 - val_accuracy: 0.5360\n",
      "Epoch 2/20\n",
      "63/63 - 63s - loss: 0.9894 - accuracy: 0.6051 - val_loss: 0.9760 - val_accuracy: 0.6340\n",
      "Epoch 3/20\n",
      "63/63 - 63s - loss: 0.9155 - accuracy: 0.6436 - val_loss: 1.0111 - val_accuracy: 0.6020\n",
      "Epoch 4/20\n",
      "63/63 - 64s - loss: 0.8182 - accuracy: 0.6748 - val_loss: 0.9643 - val_accuracy: 0.6100\n",
      "Epoch 5/20\n",
      "63/63 - 63s - loss: 0.7237 - accuracy: 0.7100 - val_loss: 0.8744 - val_accuracy: 0.6440\n",
      "Epoch 6/20\n",
      "63/63 - 66s - loss: 0.6758 - accuracy: 0.7285 - val_loss: 0.8415 - val_accuracy: 0.6880\n",
      "Epoch 7/20\n",
      "63/63 - 68s - loss: 0.6133 - accuracy: 0.7485 - val_loss: 0.8220 - val_accuracy: 0.6620\n",
      "Epoch 8/20\n",
      "63/63 - 64s - loss: 0.5537 - accuracy: 0.7827 - val_loss: 0.7995 - val_accuracy: 0.6960\n",
      "Epoch 9/20\n",
      "63/63 - 65s - loss: 0.5165 - accuracy: 0.7980 - val_loss: 0.8428 - val_accuracy: 0.6760\n",
      "Epoch 10/20\n",
      "63/63 - 58s - loss: 0.5255 - accuracy: 0.7962 - val_loss: 0.8319 - val_accuracy: 0.7080\n",
      "16/16 [==============================] - 2s 138ms/step - loss: 0.7995 - accuracy: 0.6960\n",
      "INFO:tensorflow:Assets written to: saved_models/Model 1/Run-8/assets\n",
      "--- Starting trial: run-9\n",
      "{'filter_size': 7, 'filters_number': 32}\n",
      "Epoch 1/20\n",
      "63/63 - 27s - loss: 2.1118 - accuracy: 0.4710 - val_loss: 1.1957 - val_accuracy: 0.4720\n",
      "Epoch 2/20\n",
      "63/63 - 27s - loss: 1.0318 - accuracy: 0.5924 - val_loss: 1.0190 - val_accuracy: 0.6020\n",
      "Epoch 3/20\n",
      "63/63 - 28s - loss: 0.8998 - accuracy: 0.6434 - val_loss: 0.9506 - val_accuracy: 0.6180\n",
      "Epoch 4/20\n",
      "63/63 - 26s - loss: 0.7724 - accuracy: 0.6961 - val_loss: 0.9531 - val_accuracy: 0.6100\n",
      "Epoch 5/20\n",
      "63/63 - 29s - loss: 0.7758 - accuracy: 0.6946 - val_loss: 1.0156 - val_accuracy: 0.6020\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 1s 57ms/step - loss: 0.9506 - accuracy: 0.6180\n",
      "INFO:tensorflow:Assets written to: saved_models/Model 1/Run-9/assets\n",
      "--- Starting trial: run-10\n",
      "{'filter_size': 7, 'filters_number': 64}\n",
      "Epoch 1/20\n",
      "63/63 - 60s - loss: 3.3039 - accuracy: 0.4933 - val_loss: 1.1070 - val_accuracy: 0.5320\n",
      "Epoch 2/20\n",
      "63/63 - 50s - loss: 0.9586 - accuracy: 0.6139 - val_loss: 0.9522 - val_accuracy: 0.6180\n",
      "Epoch 3/20\n",
      "63/63 - 46s - loss: 0.8653 - accuracy: 0.6648 - val_loss: 0.9320 - val_accuracy: 0.6300\n",
      "Epoch 4/20\n",
      "63/63 - 43s - loss: 0.7929 - accuracy: 0.6963 - val_loss: 0.8898 - val_accuracy: 0.6700\n",
      "Epoch 5/20\n",
      "63/63 - 42s - loss: 0.7637 - accuracy: 0.6978 - val_loss: 0.9139 - val_accuracy: 0.6620\n",
      "Epoch 6/20\n",
      "63/63 - 42s - loss: 0.6924 - accuracy: 0.7213 - val_loss: 0.9049 - val_accuracy: 0.6560\n",
      "16/16 [==============================] - 1s 86ms/step - loss: 0.8898 - accuracy: 0.6700\n",
      "INFO:tensorflow:Assets written to: saved_models/Model 1/Run-10/assets\n",
      "--- Starting trial: run-11\n",
      "{'filter_size': 7, 'filters_number': 96}\n",
      "Epoch 1/20\n",
      "63/63 - 65s - loss: 5.3025 - accuracy: 0.4573 - val_loss: 1.0942 - val_accuracy: 0.5700\n",
      "Epoch 2/20\n",
      "63/63 - 69s - loss: 0.9937 - accuracy: 0.6016 - val_loss: 0.9589 - val_accuracy: 0.6460\n",
      "Epoch 3/20\n",
      "63/63 - 63s - loss: 0.8259 - accuracy: 0.6753 - val_loss: 0.9453 - val_accuracy: 0.6480\n",
      "Epoch 4/20\n",
      "63/63 - 65s - loss: 0.7750 - accuracy: 0.6878 - val_loss: 0.8738 - val_accuracy: 0.6680\n",
      "Epoch 5/20\n",
      "63/63 - 56s - loss: 0.7000 - accuracy: 0.7263 - val_loss: 0.9274 - val_accuracy: 0.6440\n",
      "Epoch 6/20\n",
      "63/63 - 53s - loss: 0.7008 - accuracy: 0.7203 - val_loss: 0.9309 - val_accuracy: 0.6420\n",
      "16/16 [==============================] - 2s 112ms/step - loss: 0.8738 - accuracy: 0.6680\n",
      "INFO:tensorflow:Assets written to: saved_models/Model 1/Run-11/assets\n",
      "--- Starting trial: run-12\n",
      "{'filter_size': 7, 'filters_number': 128}\n",
      "Epoch 1/20\n",
      "63/63 - 71s - loss: 4.5502 - accuracy: 0.4825 - val_loss: 1.1086 - val_accuracy: 0.5260\n",
      "Epoch 2/20\n",
      "63/63 - 68s - loss: 0.9290 - accuracy: 0.6314 - val_loss: 0.9327 - val_accuracy: 0.6160\n",
      "Epoch 3/20\n",
      "63/63 - 68s - loss: 0.8174 - accuracy: 0.6756 - val_loss: 0.9422 - val_accuracy: 0.6240\n",
      "Epoch 4/20\n",
      "63/63 - 69s - loss: 0.7650 - accuracy: 0.6908 - val_loss: 0.8318 - val_accuracy: 0.6740\n",
      "Epoch 5/20\n",
      "63/63 - 68s - loss: 0.7257 - accuracy: 0.7173 - val_loss: 0.8530 - val_accuracy: 0.6620\n",
      "Epoch 6/20\n",
      "63/63 - 68s - loss: 0.6514 - accuracy: 0.7395 - val_loss: 0.8324 - val_accuracy: 0.6760\n",
      "16/16 [==============================] - 3s 178ms/step - loss: 0.8318 - accuracy: 0.6740\n",
      "INFO:tensorflow:Assets written to: saved_models/Model 1/Run-12/assets\n"
     ]
    }
   ],
   "source": [
    "session_num = 1\n",
    "\n",
    "for filter_size in HP_FILTER_SIZE.domain.values:\n",
    "    for filter_num in HP_FILTER_NUM.domain.values:\n",
    "\n",
    "        hparams = {\n",
    "            HP_FILTER_SIZE: filter_size,\n",
    "            HP_FILTER_NUM: filter_num\n",
    "        }\n",
    "\n",
    "        run_name = \"run-%d\" % session_num\n",
    "        print('--- Starting trial: %s' % run_name)\n",
    "        print({h.name: hparams[h] for h in hparams})\n",
    "        run('Logs/Model 1/hparam_tuning/' + run_name, hparams, session_num)\n",
    "\n",
    "        session_num += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading a model to evaluate on the test set\n",
    "model = tf.keras.models.load_model(r\"saved_models/Model 1/Run-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 1s 37ms/step - loss: 0.8125 - accuracy: 0.6980\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(images_test,labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.8125. Test accuracy: 69.80%\n"
     ]
    }
   ],
   "source": [
    "# Printing the test results\n",
    "print('Test loss: {0:.4f}. Test accuracy: {1:.2f}%'.format(test_loss, test_accuracy*100.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir \"Logs/Model 1/hparam_tuning\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir \"Logs/Model 1/fit\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
